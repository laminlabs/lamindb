{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "[![Jupyter Notebook](https://img.shields.io/badge/Source%20on%20GitHub-orange)](https://github.com/laminlabs/lamindb/blob/main/docs/registries.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Query & search registries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "This guide walks through different ways of querying & searching LaminDB registries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Let's start by creating a few exemplary datasets and saving them into a LaminDB instance (hidden cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# pip install 'lamindb[bionty]'\n",
    "!lamin init --storage ./test-registries --modules bionty\n",
    "\n",
    "# python\n",
    "import lamindb as ln\n",
    "import bionty as bt\n",
    "from lamindb.core import datasets\n",
    "\n",
    "ln.track(\"pd7UR7Z8hoTq0000\")\n",
    "\n",
    "# Create non-curated datasets\n",
    "ln.Artifact(datasets.file_jpg_paradisi05(), key=\"images/my_image.jpg\").save()\n",
    "ln.Artifact(datasets.file_fastq(), key=\"raw/my_fastq.fastq\").save()\n",
    "ln.Artifact.from_df(datasets.df_iris(), key=\"iris/iris_collection.parquet\").save()\n",
    "\n",
    "# Create a more complex case\n",
    "# observation-level metadata\n",
    "ln.Feature(name=\"cell_medium\", dtype=\"cat[ULabel]\").save()\n",
    "ln.Feature(name=\"sample_note\", dtype=\"str\").save()\n",
    "ln.Feature(name=\"cell_type_by_expert\", dtype=\"cat[bionty.CellType]\").save()\n",
    "ln.Feature(name=\"cell_type_by_model\", dtype=\"cat[bionty.CellType]\").save()\n",
    "# dataset-level metadata\n",
    "ln.Feature(name=\"temperature\", dtype=\"float\").save()\n",
    "ln.Feature(name=\"study\", dtype=\"cat[ULabel]\").save()\n",
    "ln.Feature(name=\"date_of_study\", dtype=\"date\").save()\n",
    "ln.Feature(name=\"study_note\", dtype=\"str\").save()\n",
    "\n",
    "## Permissible values for categoricals\n",
    "ln.ULabel.from_values([\"DMSO\", \"IFNG\"], create=True).save()\n",
    "ln.ULabel.from_values(\n",
    "    [\"Candidate marker study 1\", \"Candidate marker study 2\"], create=True\n",
    ").save()\n",
    "bt.CellType.from_values([\"B cell\", \"T cell\"], create=True).save()\n",
    "\n",
    "# Ingest dataset1\n",
    "adata = datasets.small_dataset1(otype=\"AnnData\")\n",
    "curator = ln.Curator.from_anndata(\n",
    "    adata,\n",
    "    var_index=bt.Gene.ensembl_gene_id,\n",
    "    categoricals={\n",
    "        \"cell_medium\": ln.ULabel.name,\n",
    "        \"cell_type_by_expert\": bt.CellType.name,\n",
    "        \"cell_type_by_model\": bt.CellType.name,\n",
    "    },\n",
    "    organism=\"human\",\n",
    ")\n",
    "artifact = curator.save_artifact(key=\"example_datasets/dataset1.h5ad\")\n",
    "artifact.features.add_values(adata.uns)\n",
    "\n",
    "# Ingest dataset2\n",
    "adata2 = datasets.small_dataset2(otype=\"AnnData\")\n",
    "curator = ln.Curator.from_anndata(\n",
    "    adata2,\n",
    "    var_index=bt.Gene.symbol,\n",
    "    categoricals={\n",
    "        \"cell_medium\": ln.ULabel.name,\n",
    "        \"cell_type_by_model\": bt.CellType.name,\n",
    "    },\n",
    "    organism=\"human\",\n",
    ")\n",
    "artifact2 = curator.save_artifact(key=\"example_datasets/dataset2.h5ad\")\n",
    "artifact2.features.add_values(adata2.uns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Get an overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "The easiest way to get an overview over all artifacts is by typing {meth}`~lamindb.Artifact.df`, which returns the 100 latest artifacts in the {class}`~lamindb.Artifact` registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import lamindb as ln\n",
    "\n",
    "ln.Artifact.df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "You can include fields from other registries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.df(\n",
    "    include=[\n",
    "        \"created_by__name\",\n",
    "        \"ulabels__name\",\n",
    "        \"cell_types__name\",\n",
    "        \"feature_sets__itype\",\n",
    "        \"suffix\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "You can include information about which artifact measures which `feature`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "df = ln.Artifact.df(features=True)\n",
    "ln.view(df)  # for clarity, leverage ln.view() to display dtype annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "The flattened table that includes information from all relevant registries is easier to understand than the normalized data. For comparison, here is how to see the later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.view()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Auto-complete records"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "For registries with less than 100k records, auto-completing a `Lookup` object is the most convenient way of finding a record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import bionty as bt\n",
    "\n",
    "# query the database for all ulabels or all cell types\n",
    "ulabels = ln.ULabel.lookup()\n",
    "cell_types = bt.CellType.lookup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    ":::{dropdown} Show me a screenshot\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/lgRNHNtMxjU0y8nIagt7.png\" width=\"400px\">\n",
    "\n",
    ":::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "With auto-complete, we find a ulabel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "study1 = ulabels.candidate_marker_study_1\n",
    "study1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Get one record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "{class}`~lamindb.core.Record.get` errors if more than one matching records are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "print(study1.uid)\n",
    "\n",
    "# by uid\n",
    "ln.ULabel.get(study1.uid)\n",
    "\n",
    "# by field\n",
    "ln.ULabel.get(name=\"Candidate marker study 1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Query multiple records"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Filter for all artifacts annotated by a ulabel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.filter(ulabels=study1).df()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "To access the results encoded in a filter statement, execute its return value with one of:\n",
    "\n",
    "- {meth}`~lamindb.core.QuerySet.df`: A pandas `DataFrame` with each record in a row.\n",
    "- {meth}`~lamindb.core.QuerySet.all`: A {class}`~lamindb.core.QuerySet`.\n",
    "- {meth}`~lamindb.core.QuerySet.one`: Exactly one record. Will raise an error if there is none. Is equivalent to the `.get()` method shown above.\n",
    "- {meth}`~lamindb.core.QuerySet.one_or_none`: Either one record or `None` if there is no query result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "```{note}\n",
    "\n",
    "{meth}`~lamindb.core.Record.filter` returns a {class}`~lamindb.core.QuerySet`.\n",
    "\n",
    "The registries in LaminDB are Django Models and any [Django query](https://docs.djangoproject.com/en/stable/topics/db/queries/) works.\n",
    "\n",
    "LaminDB re-interprets Django's API for data scientists.\n",
    "\n",
    "```\n",
    "\n",
    "```{dropdown} What does this have to do with SQL?\n",
    "\n",
    "Under the hood, any `.filter()` call translates into a SQL select statement.\n",
    "\n",
    "LaminDB's registries are object relational mappers (ORMs) that rely on Django for all the heavy lifting.\n",
    "\n",
    "Of note, `.one()` and `.one_or_none()` are the two parts of LaminDB's API that are borrowed from SQLAlchemy. In its first year, LaminDB built on SQLAlchemy.\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## Search for records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "You can search every registry via {meth}`~lamindb.core.Record.search`. For example, the `Artifact` registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.search(\"iris\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Here is more background on search and examples for searching the entire cell type ontology: {doc}`/faq/search` "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Query related registries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "Django has a double-under-score syntax to filter based on related tables.\n",
    "\n",
    "This syntax enables you to traverse several layers of relations and leverage different comparators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.filter(created_by__handle__startswith=\"testuse\").df()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "The filter selects all artifacts based on the users who ran the generating notebook. Under the hood, in the SQL database, it's joining the artifact table with the user table.\n",
    "\n",
    "Another typical example is querying all datasets that measure a particular feature. For instance, which datasets measure `\"CD8A\"`. Here is how to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "cd8a = bt.Gene.get(symbol=\"CD8A\")\n",
    "# query for all feature sets that contain CD8A\n",
    "feature_sets_with_cd8a = ln.Schema.filter(genes=cd8a).all()\n",
    "# get all artifacts\n",
    "ln.Artifact.filter(feature_sets__in=feature_sets_with_cd8a).df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "Instead of splitting this across three queries, the double-underscore syntax allows you to define a path for one query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.filter(feature_sets__genes__symbol=\"CD8A\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "## Filter operators"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "You can qualify the type of comparison in a query by using a comparator.\n",
    "\n",
    "Below follows a list of the most import, but Django supports about [two dozen field comparators](https://docs.djangoproject.com/en/stable/ref/models/querysets/#field-lookups) `field__comparator=value`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "### and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.filter(suffix=\".h5ad\", ulabels=study1).df()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "### less than/ greater than"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "Or subset to artifacts greater than 10kB. Here, we can't use keyword arguments, but need an explicit where statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.filter(ulabels=study1, size__gt=1e4).df()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "### in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.filter(suffix__in=[\".jpg\", \".fastq.gz\"]).df()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "### order by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.filter().order_by(\"created_at\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# reverse ordering\n",
    "ln.Artifact.filter().order_by(\"-created_at\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.filter().order_by(\"key\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse ordering\n",
    "ln.Artifact.filter().order_by(\"-key\").df()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "### contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Transform.filter(name__contains=\"search\").df().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "And case-insensitive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Transform.filter(name__icontains=\"Search\").df().head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "### startswith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Transform.filter(name__startswith=\"Research\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "### or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.filter(ln.Q(suffix=\".jpg\") | ln.Q(suffix=\".fastq.gz\")).df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "### negate/ unequal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.filter(~ln.Q(suffix=\".jpg\")).df()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
