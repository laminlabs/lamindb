{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://img.shields.io/badge/tutorial2/2-lightgrey)\n",
    "[![](https://img.shields.io/badge/Jupyter%20Notebook-orange)](https://github.com/laminlabs/lamindb/blob/main/docs/tutorial1.ipynb)\n",
    "[![](https://img.shields.io/badge/laminlabs/lamindata-mediumseagreen)](https://lamin.ai/laminlabs/lamindata/record/core/Transform?id=dMtrt8YMSdl6z8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Features & labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous tutorial ({doc}`/tutorial`), we learned about about how to leverage basic metadata for files & datasets to access data (query, search, stage & load).\n",
    "\n",
    "Here, we walk through annotating & validating data with features & labels to improve:\n",
    "\n",
    "1. Finding data: Which datasets measured expression of cell marker `CD14`? Which characterized cell line `K562`? Which datasets have a test & train split? Etc.\n",
    "2. Using data: Are there typos in feature names? Are there typos in sampled labels? Are units of features consistent? Etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} What was LaminDB's most basic inspiration?\n",
    "\n",
    "The pydata family of objects is at the heart of most data science, ML & comp bio workflows: `DataFrame`, `AnnData`, `pytorch.DataLoader`, `zarr.Array`, `pyarrow.Table`, `xarray.Dataset`, ...\n",
    "\n",
    "And still, we couldnâ€™t find a tool to link these objects to context so that they could be analyzed in context!\n",
    "\n",
    "Context relevant for analyses includes anything that's needed to interpret & model data.\n",
    "\n",
    "So, `lamindb.File` and `lamindb.Dataset` track:\n",
    "\n",
    "- data sources, data transformations, models, users & pipelines that performed transformations (provenance)\n",
    "- any entity of the domain in which data is generated and modeled (features & labels)\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lamindb as ln\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.settings.verbosity = \"hint\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We study 3 organism of the Iris plant: `setosa`, `versicolor` & `virginica`.\n",
    "\n",
    "Let's populate the universal (untyped) label registry ({class}`~lamindb.ULabel`) for them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [ln.ULabel(name=name) for name in [\"setosa\", \"versicolor\", \"virginica\"]]\n",
    "ln.save(labels)\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anticipating that we'll have many different labels when working with more data, we'd like to express that all 3 labels are organism labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent = ln.ULabel(name=\"is_organism\")\n",
    "parent.save()\n",
    "\n",
    "for label in labels:\n",
    "    label.parents.add(parent)\n",
    "\n",
    "parent.view_parents(with_children=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{class}`~lamindb.ULabel` enables you to manage an in-house ontology to manage all kinds of _untyped_ labels.\n",
    "\n",
    "If you'd like to leverage pre-built _typed_ ontologies for basic biological entities in the same way, see: {doc}`/bio-registries`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to organism, we'd like to track the studies that produced the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.ULabel(name=\"study0\").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} Why label a data batch by study?\n",
    "\n",
    "We can then\n",
    "\n",
    "1. query all files link to this experiment\n",
    "2. model it as a confounder when we'll analyze similar data from a follow-up experiment, and concatenate data using the label as a feature in a data matrix\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every set of studied labels (measured values), we typically also want an identifier for the corresponding measurement dimension: the feature.\n",
    "\n",
    "When we integrate data batches, feature names will label columns that store data.\n",
    "\n",
    "Let's create and save two {class}`~lamindb.Feature` records to identify measurements of the iris organism label and the study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.Feature(name=\"iris_organism_name\", type=\"category\").save()\n",
    "ln.Feature(name=\"study_name\", type=\"category\").save()\n",
    "# create a lookup object so that we can access features with auto-complete\n",
    "features = ln.Feature.lookup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate & link labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already looked at the metadata for `study0`, before: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_file = ln.File.filter(key=\"iris_studies/study0_raw_images/meta.csv\").one()\n",
    "meta = meta_file.load(index_col=0)  # load a dataframe\n",
    "\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the data generation process, such metadata might or might not match the labels we defined in our registries.\n",
    "\n",
    "Let's validate the labels by mapping the values stored in the file on the :class:`~lamindb.ULabel` registry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.ULabel.validate(meta[\"1\"], field=\"name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything passed and no fixes are needed!\n",
    "\n",
    "If validation doesn't pass, {meth}`~lamindb.dev.CanValidate.standardize` and {meth}`~lamindb.dev.CanValidate.inspect` will help curate data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeling a set of files is useful if we want to make the set queryable among a large number of files.\n",
    "\n",
    "You can label a file by calling `file.labels.add()` and pass a single or multiple label records.\n",
    "\n",
    "Let's do this based on the labels in `meta.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "image_files = ln.File.filter(\n",
    "    key__startswith=\"iris_studies/study0_raw_images\", suffix=\".jpg\"\n",
    ")\n",
    "\n",
    "study_label = ln.ULabel.filter(name=\"study0\").one()\n",
    "for file in image_files:\n",
    "    file.labels.add(study_label, feature=features.study_name)\n",
    "    # get organism name from metadata file\n",
    "    organism_name = meta.loc[file.path.name == meta[\"0\"], \"1\"].values[0]\n",
    "    organism_label = ln.ULabel.filter(name=organism_name).one()\n",
    "    file.labels.add(organism_label, feature=features.iris_organism_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query files by labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the new annotations, you can now query image files by organism & study labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ln.ULabel.lookup()\n",
    "file = ln.File.filter(ulabels__in=[labels.versicolor, labels.study0]).first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also see them when calling {meth}`~lamindb.dev.Data.describe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeling datasets works in the same way as labeling files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# query the dataset\n",
    "dataset = ln.Dataset.filter(name=\"Iris study 1\").one()\n",
    "\n",
    "# add study label\n",
    "dataset.labels.add(study_label, feature=features.study_name)\n",
    "\n",
    "# get all organism labels\n",
    "all_organism_labels = ln.ULabel.filter(parents__name=\"is_organism\").all()\n",
    "dataset.labels.add(all_organism_labels, feature=features.iris_organism_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the dataset is labeled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run an ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now run a ML model that transforms the images into 4 high-level features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "def run_ml_model() -> pd.DataFrame:\n",
    "    transform = ln.Transform(name=\"Petal & sepal regressor\", type=\"pipeline\")\n",
    "    ln.track(transform)\n",
    "    input_dataset = ln.Dataset.filter(name=\"Iris study 1\").one()\n",
    "    input_paths = [file.stage() for file in input_dataset.files.all()]\n",
    "    # transform the data...\n",
    "    output_dataset = ln.dev.datasets.df_iris_in_meter_study1()\n",
    "    return output_dataset\n",
    "\n",
    "\n",
    "df = run_ml_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is the ML pipeline that produced the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.run_context.transform.view_parents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the output data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first register the features of the transformed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = ln.Feature.from_df(df)\n",
    "ln.save(new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} How to track units of features?\n",
    "\n",
    "Use the `unit` field of {class}`~lamindb.Feature`. In the above example, you'd do:\n",
    "\n",
    "```python\n",
    "for feature in features:\n",
    "    if feature.type == \"number\":\n",
    "        feature.unit = \"m\"  # SI unit for meters\n",
    "        feature.save()\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now validate & register the dataframe in one line by creating a {class}`~lamindb.Dataset` record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ln.Dataset.from_df(\n",
    "    df,\n",
    "    name=\"Iris study 1 - transformed\",\n",
    "    description=\"Iris dataset after measuring sepal & petal metrics\",\n",
    ")\n",
    "\n",
    "dataset.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an overview of linked features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see that they're always grouped in sets that correspond to records of {class}`~lamindb.FeatureSet`.\n",
    "\n",
    ":::{dropdown} Why does LaminDB model feature sets, not just features?\n",
    "\n",
    "1. Performance: Imagine you measure the same panel of 20k transcripts in 1M samples. By modeling the panel as a feature set, you'll only need to store 1M instead of 1M x 20k = 20B links.\n",
    "2. Interpretation: Model protein panels, gene panels, etc.\n",
    "3. Data integration: Feature sets provide the currency that determines whether two datasets can be easily concatenated.\n",
    "\n",
    "These reasons do not hold for label sets. Hence, LaminDB does not model label sets.\n",
    "\n",
    ":::\n",
    "\n",
    "A `slot` provides a string key to access feature sets. It's typically the accessor within the registered data object, here `pd.DataFrame.columns`.\n",
    "\n",
    "Let's use it to access all linked features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.features[\"columns\"].df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one categorical feature, let's add the organism labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organism_labels = ln.ULabel.filter(parents__name=\"is_organism\").all()\n",
    "dataset.labels.add(organism_labels, feature=features.iris_organism_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now add study labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.labels.add(study_label, feature=features.study_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the `columns` feature set, we now have an `external` feature set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the context for our file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.file.view_flow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the database content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.view(registries=[\"Feature\", \"FeatureSet\", \"ULabel\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage follow-up data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that a couple of weeks later, we receive a new batch of data in a follow-up study 2.\n",
    "\n",
    "Let's track a new analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.track()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register a joint dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we already ran all preprocessing including the ML model.\n",
    "\n",
    "We get a DataFrame and store it as a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "df = ln.dev.datasets.df_iris_in_meter_study2()\n",
    "ln.File.from_df(df, description=\"Iris study 2 - transformed\").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load both data batches as files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = ln.Dataset.filter(name=\"Iris study 1 - transformed\").one()\n",
    "\n",
    "file1 = dataset1.file\n",
    "file2 = ln.File.filter(description=\"Iris study 2 - transformed\").one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now store the joint dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ln.Dataset([file1, file2], name=\"Iris flower study 1 & 2 - transformed\")\n",
    "\n",
    "dataset.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-concatenate data batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because both data batches measured the same validated feature set, we can auto-concatenate the sharded dataset.\n",
    "\n",
    "This means, we can load it as if it was stored in a single file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.load().tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access & query the underlying two file objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.files.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or look at their data flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.view_flow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or look at the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is it! ðŸ˜…\n",
    "\n",
    "If you're interested, please check out guides & use cases or make an issue on GitHub to [discuss](https://github.com/laminlabs/lamindb/issues/new)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hierarchical ontologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say, we want to express that `study0` belongs to project 1 and is a study, we can use `.parents`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project1 = ln.ULabel(name=\"project1\")\n",
    "project1.save()\n",
    "is_study = ln.ULabel(name=\"is_study\")\n",
    "is_study.save()\n",
    "study_label.parents.set([project1, is_study])\n",
    "study_label.view_parents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more info, see {meth}`~lamindb.dev.HasParents.view_parents`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avoid duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already created a `project1` label before, let's see what happens if we try to create it again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ln.ULabel(name=\"project1\")\n",
    "\n",
    "label.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of creating a new record, LaminDB loads and returns the existing record from the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is no exact match, LaminDB will warn you upon creating a record about potential duplicates.\n",
    "\n",
    "Say, we spell \"project 1\" with a white space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.ULabel(name=\"project 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid inserting duplicates when creating new records, a search compares whether a similar record already exists.\n",
    "\n",
    "You can switch it off for performance gains via {attr}`~lamindb.dev.Settings.upon_create_search_names`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update & delete records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ln.ULabel.filter(name=\"project1\").first()\n",
    "\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.name = \"project1a\"\n",
    "\n",
    "label.save()\n",
    "\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change default storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default storage location is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.settings.storage  # your \"working data directory\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change it by setting `ln.settings.storage = \"s3://my-bucket\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See all storage locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.Storage.filter().df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set verbosity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the number of logging messages, set {attr}`~lamindb.dev.Settings.verbosity`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.settings.verbosity = 3  # only show info, no hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up what we wrote in this notebook\n",
    "!lamin delete --force lamin-tutorial\n",
    "!rm -r lamin-tutorial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "nbproject": {
   "id": "dMtrt8YMSdl6",
   "parent": null,
   "pypackage": null,
   "time_init": "2023-08-22T08:45:25.751949+00:00",
   "user_handle": "testuser1",
   "user_id": "DzTjkKse",
   "user_name": "Test User1",
   "version": "0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
