{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage notebooks, scripts & workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have a `lamindb` instance, here's how to create one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "!lamin init --storage ./test-track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage notebooks and scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call {meth}`~lamindb.track` to save your notebook or script as a `transform` and start tracking inputs & outputs of a run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{eval-rst}\n",
    ".. literalinclude:: scripts/run_track_and_finish.py\n",
    "   :language: python\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You find your notebooks and scripts in the {class}`~lamindb.Transform` registry along with pipelines & functions:\n",
    "\n",
    "```python\n",
    "transform = ln.Transform.get(key=\"my_analyses/my_notebook.ipynb\")\n",
    "transform.source_code             # source code\n",
    "transform.runs.to_dataframe()     # all runs in a dataframe\n",
    "transform.latest_run.report       # report of latest run\n",
    "transform.latest_run.environment  # environment of latest run\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the CLI to load a transform into your current (development) directory:\n",
    "\n",
    "```bash\n",
    "lamin load --key my_analyses/my_notebook.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your instance is connected to LaminHub, you can search or filter the `transform` page and explore data lineage:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{raw} html\n",
    "<video width=\"500\" controls>\n",
    "  <source src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/Xdiikc2c1tPtHcvF0000.mp4\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "</video>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how you'd load the [notebook from the video](https://lamin.ai/laminlabs/lamindata/transform/F4L3oC6QsZvQ) into your local directory:\n",
    "\n",
    "```bash\n",
    "lamin load https://lamin.ai/laminlabs/lamindata/transform/F4L3oC6QsZvQ\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize local development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no development directory is set, script & notebooks keys equal their filenames.\n",
    "Otherwise, script & notebooks keys equal the relative path in the development directory.\n",
    "\n",
    "To set the development directory to your current shell development directory, run:\n",
    "\n",
    "```bash\n",
    "lamin settings set dev-dir .\n",
    "```\n",
    "\n",
    "You can see the current status by running:\n",
    "\n",
    "```bash\n",
    "lamin info\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can link the entities created during a run to a project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import lamindb as ln\n",
    "\n",
    "my_project = ln.Project(name=\"My project\").save()  # create & save a project\n",
    "ln.track(project=\"My project\")  # pass project\n",
    "open(\"sample.fasta\", \"w\").write(\">seq1\\nACGT\\n\")  # create a dataset\n",
    "ln.Artifact(\"sample.fasta\", key=\"sample.fasta\").save()  # auto-labeled by project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter entities by project, e.g., artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.filter(projects=my_project).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access entities linked to a project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "my_project.artifacts.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same works for `my_project.transforms` or `my_project.runs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can write the entities created during a run into a space that you configure on LaminHub. This is particularly useful if you want to restrict access to a space. Note that this doesn't affect bionty entities who should typically be commonly accessible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "ln.track(space=\"Our team space\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(sync-code-with-git)=\n",
    "\n",
    "### Sync code with git\n",
    "\n",
    "To sync scripts or workflows with their correponding files in a git repo, either export an environment variable:\n",
    "\n",
    "```shell\n",
    "export LAMINDB_SYNC_GIT_REPO = <YOUR-GIT-REPO-URL>\n",
    "```\n",
    "\n",
    "Or set the following setting:\n",
    "\n",
    "```python\n",
    "ln.settings.sync_git_repo = <YOUR-GIT-REPO-URL>\n",
    "```\n",
    "\n",
    "If you work on a single project in your lamindb instance, it makes sense to set LaminDB's `dev-dir` to the root of the local git repo clone.\n",
    "\n",
    "```bash\n",
    "dbs/\n",
    "  project1/\n",
    "    .git/\n",
    "    script1.py\n",
    "    notebook1.ipynb\n",
    "  ...\n",
    "```\n",
    "\n",
    "If you work on multiple projects in your lamindb instance, you can use the `dev-dir` as the local root and nest git repositories in it.\n",
    "\n",
    "```bash\n",
    "dbs/\n",
    "  database1/\n",
    "    repo1/\n",
    "      .git/\n",
    "    repo2/\n",
    "      .git/\n",
    "  ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(manage-workflows)=\n",
    "\n",
    "## Manage workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll manage workflows with `lamindb`'s {func}`~lamindb.flow` and {func}`~lamindb.step` decorators, which works out-of-the-box with the majority of Python workflow managers:\n",
    "\n",
    "| tool | workflow decorator | step/task decorator | notes |\n",
    "|------|-------------------|-------------------|-------|\n",
    "| `lamindb` | `@flow` | `@step` | inspired by `prefect` | \n",
    "| `prefect` | `@flow` | `@task` | two decorators |\n",
    "| `redun` | `@task` (on main) | `@task` | single decorator for everything |\n",
    "| `dagster` | `@job` or `@asset` | `@op` or `@asset` | asset-centric; `@asset` is primary |\n",
    "| `flyte` | `@workflow` | `@task` | also `@dynamic` for runtime DAGs |\n",
    "| `airflow` | `@dag` | `@task` | TaskFlow API (modern); also supports operators |\n",
    "| `zenml` | `@pipeline` | `@step` | inspired by `prefect` |\n",
    "\n",
    "If you're looking for more in-depth examples or for integrating with non-decorator-based workflow managers such as Nextflow or Snakemake, see {doc}`docs:workflows`.\n",
    "\n",
    "| tool | workflow | step/task | notes |\n",
    "|------|-------------------|-------------------|-------|\n",
    "| `nextflow` | `workflow` keyword | `process` keyword | groovy-based DSL |\n",
    "| `snakemake` | `rule` keyword | `rule` keyword | file-based DSL | \n",
    "| `metaflow` | `FlowSpec` | `@step` | class-based |\n",
    "| `kedro` | `Pipeline()` | `node()` | function-based |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A one-step workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decorate a function with {func}`~lamindb.flow` to track it as a workflow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{eval-rst}\n",
    ".. literalinclude:: scripts/my_workflow.py\n",
    "   :language: python\n",
    "   :caption: my_workflow.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "!python scripts/my_workflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the workflow via its filename:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "transform = ln.Transform.get(key=\"my_workflow.py\")\n",
    "transform.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The run stored the parameter value for `key`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "transform.latest_run.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It links output artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "transform.latest_run.output_artifacts.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can query for all runs that ran with that parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Run.filter(\n",
    "    params__key=\"my_analysis/dataset.parquet\",\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass complex parameters and features, see: {ref}`track-run-parameters`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A multi-step workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the workflow calls an additional processing step:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{eval-rst}\n",
    ".. literalinclude:: scripts/my_workflow_with_step.py\n",
    "   :language: python\n",
    "   :caption: my_workflow_with_step.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "!python scripts/my_workflow_with_step.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lineage of the subsetted artifact resolves the subsetting step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetted_artifact = ln.Artifact.get(key=\"my_analysis/dataset_subsetted.parquet\")\n",
    "subsetted_artifact.view_lineage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the run that created the subsetted_artifact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "subsetted_artifact.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the initating run that triggered the function call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "subsetted_artifact.run.initiated_by_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the parameters of the run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "subsetted_artifact.run.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the input artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "subsetted_artifact.run.input_artifacts.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are output artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "subsetted_artifact.run.output_artifacts.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A workflow with CLI arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `click` to parse CLI arguments:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{eval-rst}\n",
    ".. literalinclude:: scripts/my_workflow_with_click.py\n",
    "   :language: python\n",
    "   :caption: my_workflow_with_click.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "!python scripts/my_workflow_with_click.py --key my_analysis/dataset2.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLI arguments are tracked and accessible via `run.cli_args`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "run = ln.Run.filter(transform__key=\"my_workflow_with_click.py\").first()\n",
    "run.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it doesn't matter whether you use `click`, `argparse`, or any other CLI argument parser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(track-run-parameters)=\n",
    "\n",
    "## Track parameters & features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just saw that the function decorators `@ln.flow()` and `@ln.step()` track parameter values automatically. Here is how to pass parameters to `ln.track()`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{eval-rst}\n",
    ".. literalinclude:: scripts/run_track_with_params.py\n",
    "   :language: python\n",
    "   :caption: run_track_with_params.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "!python scripts/run_track_with_params.py  --input-dir ./mydataset --learning-rate 0.01 --downsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query for all runs that match certain parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Run.filter(\n",
    "    params__learning_rate=0.01,\n",
    "    params__preprocess_params__downsample=True,\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe & get parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "run = ln.Run.filter(params__learning_rate=0.01).order_by(\"-started_at\").first()\n",
    "run.describe()\n",
    "run.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also access the CLI arguments used to start the run directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "run.cli_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also track run features in analogy to artifact features.\n",
    "\n",
    "In contrast to params, features are validated against the `Feature` registry and allow to express relationships with entities in your registries.\n",
    "\n",
    "Let's first define labels & features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "experiment_type = ln.Record(name=\"Experiment\", is_type=True).save()\n",
    "experiment_label = ln.Record(name=\"Experiment1\", type=experiment_type).save()\n",
    "ln.Feature(name=\"s3_folder\", dtype=str).save()\n",
    "ln.Feature(name=\"experiment\", dtype=experiment_type).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "!python scripts/run_track_with_features_and_params.py  --s3-folder s3://my-bucket/my-folder --experiment Experiment1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Run.filter(s3_folder=\"s3://my-bucket/my-folder\").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe & get feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "run2 = ln.Run.filter(\n",
    "    s3_folder=\"s3://my-bucket/my-folder\", experiment=\"Experiment1\"\n",
    ").last()\n",
    "run2.describe()\n",
    "run2.features.get_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage functions in scripts and notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want more-fined-grained data lineage tracking in a script or notebook where you called `ln.track()`, you can also use the `step()` decorator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In a notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "@ln.step()\n",
    "def subset_dataframe(\n",
    "    input_artifact_key: str,\n",
    "    output_artifact_key: str,\n",
    "    subset_rows: int = 2,\n",
    "    subset_cols: int = 2,\n",
    ") -> None:\n",
    "    artifact = ln.Artifact.get(key=input_artifact_key)\n",
    "    dataset = artifact.load()\n",
    "    new_data = dataset.iloc[:subset_rows, :subset_cols]\n",
    "    ln.Artifact.from_dataframe(new_data, key=output_artifact_key).save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ln.examples.datasets.mini_immuno.get_dataset1(otype=\"DataFrame\")\n",
    "input_artifact_key = \"my_analysis/dataset.parquet\"\n",
    "artifact = ln.Artifact.from_dataframe(df, key=input_artifact_key).save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the function with default params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ouput_artifact_key = input_artifact_key.replace(\".parquet\", \"_subsetted.parquet\")\n",
    "subset_dataframe(input_artifact_key, ouput_artifact_key, subset_rows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query for the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetted_artifact = ln.Artifact.get(key=ouput_artifact_key)\n",
    "subsetted_artifact.view_lineage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-run the function with a different parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "subsetted_artifact = subset_dataframe(\n",
    "    input_artifact_key, ouput_artifact_key, subset_cols=3\n",
    ")\n",
    "subsetted_artifact = ln.Artifact.get(key=ouput_artifact_key)\n",
    "subsetted_artifact.view_lineage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a new run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "subsetted_artifact.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With new parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "subsetted_artifact.run.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a new version of the output artifact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "subsetted_artifact.run.output_artifacts.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In a script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{eval-rst}\n",
    ".. literalinclude:: scripts/run_script_with_step.py\n",
    "   :language: python\n",
    "   :caption: run_script_with_step.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "!python scripts/run_script_with_step.py --subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the state of the database after we ran these different examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage notebook templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook acts like a template upon using `lamin load` to load it. Consider you run:\n",
    "\n",
    "```bash\n",
    "lamin load https://lamin.ai/account/instance/transform/Akd7gx7Y9oVO0000\n",
    "```\n",
    "\n",
    "Upon running the returned notebook, you'll automatically create a new version and be able to browse it via the version dropdown on the UI.\n",
    "\n",
    "Additionally, you can:\n",
    "\n",
    "- label using `ULabel` or `Record`, e.g., `transform.records.add(template_label)`\n",
    "- tag with an indicative `version` string, e.g., `transform.version = \"T1\"; transform.save()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} Saving a notebook as an artifact\n",
    "\n",
    "Sometimes you might want to save a notebook as an artifact. This is how you can do it:\n",
    "\n",
    "```bash\n",
    "lamin save template1.ipynb --key templates/template1.ipynb --description \"Template for analysis type 1\" --registry artifact\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few checks at the end of this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert run.params == {\n",
    "    \"input_dir\": \"./mydataset\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"preprocess_params\": {\"downsample\": True, \"normalization\": \"the_good_one\"},\n",
    "}, run.params\n",
    "assert my_project.artifacts.exists()\n",
    "assert my_project.transforms.exists()\n",
    "assert my_project.runs.exists()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "nbproject": {
   "id": "9priar0hoE5u",
   "parent": null,
   "pypackage": null,
   "time_init": "2023-12-04T18:09:49.226879+00:00",
   "user_handle": null,
   "user_id": null,
   "user_name": null,
   "version": "0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
