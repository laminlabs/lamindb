{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track data lineage: `Pipeline`, `Notebook`, `Run`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a `Run`?\n",
    "\n",
    "{class}`~lamindb.File` are transformed by instances of {class}`~lamindb.Run`. They are the {attr}`~lamindb.Run.inputs` and {attr}`~lamindb.Run.outputs` of runs.\n",
    "\n",
    "Conversely, the {attr}`~lamindb.File.source` of {class}`~lamindb.File` is always the output of a run!\n",
    "\n",
    "A `Run` itself points to the {class}`~lamindb.Transform` object that's being run, either a `notebook` or a `pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lamindb as ln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metadata of Jupyter notebooks is automatically detected and `ln.Run` assumes `global_context=True`: we don't need to keep track of the run record ourselves, but can access it via `ln.context`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.track()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.context.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us query where `File` \"iris_new\" has been ingested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.select(ln.Transform).join(ln.Run).join(ln.File, name=\"iris_new\").first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can query for the run that contains a notebook attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ln.Session() as ss:\n",
    "    file = ss.select(ln.File, name=\"iris_new\").one()\n",
    "    print(file.source.transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "filepath = ln.dev.datasets.file_fastq()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with a pipeline, we'll register it before running it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = ln.add(ln.Transform(name=\"10x scRNA-seq nextseq\", v=\"1\"))\n",
    "\n",
    "transform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the {func}`~lamindb.track` as before (if we don't register a pipeline with the correct name, we'll be asked to):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.track(transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_fastq = ln.File(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.add(file_fastq)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also manually pass a run and not use the global run context (`ln.context`) set by `ln.track`:\n",
    "```\n",
    "run = ln.Run(transform=transform, name=\"ingest-fastq\")\n",
    "ln.File(filepath, source=run)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track run inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While run outputs are automatically tracked as data sources, run inputs aren't.\n",
    "\n",
    "However, you can simply call `is_run_input` upon loading `File`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's register a downstream pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.track(transform=ln.Transform(name=\"Cell Ranger\", v=\"7\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's query input data for this pipeline, a fastq.\n",
    "\n",
    "To process in the pipeline, we need to `load()` it (download it from the cloud and access the on-disk or in-memory representation).\n",
    "\n",
    "To track it as an input for the current run, set `is_run_input=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ln.Session() as ss:\n",
    "    file_fastq = ss.select(ln.File, name=\"input\").one()\n",
    "    file_fastq.load(is_run_input=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_fastq.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.add(file_fastq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "output_filepath = ln.dev.datasets.file_bam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = ln.File(output_filepath)\n",
    "\n",
    "ln.add(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data lineage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's track from which files that the `output.bam` file is generated, aka, the input file of the run that produced file `output.bam`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ln.Session() as ss:\n",
    "    run = ss.select(ln.Run).join(ln.File, name=\"output\", suffix=\".bam\").one()\n",
    "    assert run.inputs[0].name == \"input\"\n",
    "    print(run.inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "nbproject": {
   "id": "1LCd8kco9lZU",
   "parent": null,
   "pypackage": null,
   "time_init": "2023-01-23T13:53:15.227959+00:00",
   "user_handle": "testuser1",
   "user_id": "DzTjkKse",
   "user_name": "Test User1",
   "version": "0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ae1fefc8646a06dd2e75004cd934adda7c5727b046986a772e3b44b0ffba9754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
