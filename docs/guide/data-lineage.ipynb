{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track data lineage / provenance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you track data lineage, you'll know where your files (& datasets) came from.\n",
    "\n",
    "In this guide, you'll learn how to backtrace file transformations through notebooks, pipelines, apps & users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# initialize a test instance for this notebook\n",
    "# this should be called *before* importing lamindb in Python\n",
    "# if you'd like to load or init an instance after, use the Python API: ln.setup.init(...)\n",
    "!lamin login testuser1\n",
    "!lamin init --storage ./mydata\n",
    "!lamin login testuser2\n",
    "!lamin load testuser1/mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lamindb as ln\n",
    "\n",
    "ln.settings.verbosity = 3  # show hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# let's simulate an instrument upload for the sake of this guide\n",
    "bfx_run_output = ln.dev.datasets.generate_cell_ranger_files(\n",
    "    \"schmidt22_perturbseq\", basedir=ln.settings.storage, output_only=False\n",
    ")\n",
    "ln.setup.login(\"testuser1\")\n",
    "transform = ln.Transform(name=\"Chromium 10x upload\", type=\"pipeline\")\n",
    "ln.track(transform)\n",
    "file1 = ln.File(bfx_run_output.parent / \"fastq/schmidt22_perturbseq_R1_001.fastq.gz\")\n",
    "file1.save()\n",
    "file2 = ln.File(bfx_run_output.parent / \"fastq/schmidt22_perturbseq_R2_001.fastq.gz\")\n",
    "file2.save()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track pipelines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with a pipeline, we'll register it before running it.\n",
    "\n",
    "This only happens once and could be done by anyone on your team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.Transform(name=\"Cell Ranger\", version=\"7.2.0\", type=\"pipeline\").save()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user who runs the pipeline queries or searches for it (let's simulate another user queries the pipeline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ln.setup.login(\"testuser2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = ln.Transform.select(name=\"Cell Ranger\", version=\"7.2.0\").one()\n",
    "# or search\n",
    "# transform = ln.Transform.search(\"Cell Ranger\", return_queryset=True).first()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And passes the record to {func}`~lamindb.track`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.track(transform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a global run context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.context.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.context.run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's stage a few files from an instrument upload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ln.File.select(key__startswith=\"fastq/\").all()\n",
    "filepaths = [file.stage() for file in files]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we processed them and obtained 3 output files in a folder 'filtered_feature_bc_matrix':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree {bfx_run_output / \"filtered_feature_bc_matrix/\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_files = ln.File.from_dir(bfx_run_output / \"filtered_feature_bc_matrix/\")\n",
    "ln.save(out_files)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these files now has transform and run records that are not `None`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_files[0].transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_files[0].run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hidden cell below simulates additional analytic steps including: uploading phenotypic screen data, scRNA analysis and integration analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# continue with more precessing steps of the cell ranger output data\n",
    "transform = ln.Transform(\n",
    "    name=\"Preprocess Cell Ranger outputs\", version=\"2.0\", type=\"pipeline\"\n",
    ")\n",
    "ln.track(transform)\n",
    "\n",
    "[f.stage() for f in out_files]\n",
    "filepath = ln.dev.datasets.schmidt22_perturbseq(basedir=ln.settings.storage)\n",
    "file = ln.File(filepath, description=\"schmidt22_perturbseq counts\")\n",
    "file.save()\n",
    "ln.setup.login(\"testuser1\")\n",
    "transform = ln.Transform(name=\"Upload GWS CRISPRa result\", type=\"app\")\n",
    "ln.track(transform)\n",
    "\n",
    "# upload and analyze the GWS data\n",
    "filepath = ln.dev.datasets.schmidt22_crispra_gws_IFNG(ln.settings.storage)\n",
    "file = ln.File(filepath, description=\"Raw data of schmidt22 crispra GWS\")\n",
    "file.save()\n",
    "ln.setup.login(\"testuser2\")\n",
    "transform = ln.Transform(name=\"GWS CRIPSRa analysis\", type=\"notebook\")\n",
    "ln.track(transform)\n",
    "\n",
    "file_wgs = ln.File.select(key=\"schmidt22-crispra-gws-IFNG.csv\").one()\n",
    "df = file_wgs.load().set_index(\"id\")\n",
    "hits_df = df[df[\"pos|fdr\"] < 0.01].copy()\n",
    "file_hits = ln.File(hits_df, description=\"hits from schmidt22 crispra GWS\")\n",
    "file_hits.save()\n",
    "\n",
    "# integrate perturb-seq with WGS\n",
    "transform = ln.Transform(\n",
    "    name=\"Perform single cell analysis, integrating with CRISPRa screen\",\n",
    "    type=\"notebook\",\n",
    ")\n",
    "ln.track(transform)\n",
    "\n",
    "file_ps = ln.File.select(key=\"schmidt22_perturbseq.h5ad\").one()\n",
    "adata = file_ps.load()\n",
    "screen_hits = file_hits.load()\n",
    "import scanpy as sc\n",
    "\n",
    "sc.tl.score_genes(adata, adata.var_names.intersection(screen_hits.index).tolist())\n",
    "filesuffix = \"_fig1_score-wgs-hits.png\"\n",
    "sc.pl.umap(adata, color=\"score\", show=False, save=filesuffix)\n",
    "filepath = f\"figures/umap{filesuffix}\"\n",
    "file = ln.File(filepath, key=filepath)\n",
    "file.save()\n",
    "filesuffix = \"fig2_score-wgs-hits-per-cluster.png\"\n",
    "sc.pl.matrixplot(\n",
    "    adata, groupby=\"cluster_name\", var_names=[\"score\"], show=False, save=filesuffix\n",
    ")\n",
    "filepath = f\"figures/matrixplot_{filesuffix}\"\n",
    "file = ln.File(filepath, key=filepath)\n",
    "file.save()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track notebooks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now track a notebook. In many editors you can simply call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.track()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load one of the figure files produced from the data integration analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = ln.File.select(key__contains=\"figures/matrixplot\").one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.stage()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data lineage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two simple ways for visualizing data lineage."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a transform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first way starts from a notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = ln.Transform.search(\"Track data lineage\", return_queryset=True).first()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing parent transforms and data is straight-forward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform.parents.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform.view_parents()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you or another user re-runs a notebook, they'll immediately be informed about parents (see 'Parent transform:' from the logging messages):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.track()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.view_lineage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(file.input_of.all()) > 0\n",
    "assert len(ln.context.transform.parents.all()) > 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand runs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under-the-hood we already tracked pipeline and notebook runs through the global context: `context.run`.\n",
    "\n",
    "You can see this most easily by looking at the `File.run` attribute (in addition to `File.transform`).\n",
    "\n",
    "{class}`~lamindb.File` objects are the `inputs` and `outputs` of such runs. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, we don't want to create a global run context but manually pass a run when creating a file:\n",
    "```\n",
    "ln.File(filepath, run=ln.Run(transform=transform))\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When accessing files (_staging_, _loading_, etc.) are two things:\n",
    "\n",
    "1. The current run gets added to `file.input_of` of the file that is accessed from the transform\n",
    "2. The transform of that file got linked as a parent to the current transform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While run outputs are _automatically_ tracked as data sources once you call `ln.track()`, you can then still switch off auto-tracking of run inputs if you set `ln.settings.track_run_inputs = False`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also track run inputs on a case by case basis via `is_run_input=True`, e.g., here:\n",
    "```\n",
    "file.load(is_run_input=True)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query by provenance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can query or search for the notebook that created the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = ln.Transform.search(\"Track data lineage\", return_queryset=True).first()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then find all the files created by that notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.File.select(transform=transform).df()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that now, we have two transform records in the `Transform` registry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.view()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which transform ingested a given file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = ln.File.select().first()\n",
    "file.transform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And which user?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.created_by"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which transforms were created by a given user?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = ln.User.lookup(field=\"handle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.Transform.select(created_by=users.testuser1).df()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which notebooks were created by a given user?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.Transform.select(created_by=users.testuser1, type=\"notebook\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!lamin login testuser1\n",
    "!lamin delete mydata\n",
    "!rm -r ./mydata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "nbproject": {
   "id": "1LCd8kco9lZU",
   "parent": null,
   "pypackage": null,
   "time_init": "2023-01-23T13:53:15.227959+00:00",
   "user_handle": "testuser1",
   "user_id": "DzTjkKse",
   "user_name": "Test User1",
   "version": "0"
  },
  "vscode": {
   "interpreter": {
    "hash": "61b4062b24dfb1010f420dad5aa3bd73a4d2af47d0ec44eafec465a35a9d7239"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
