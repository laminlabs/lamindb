{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Jupyter Notebook](https://img.shields.io/badge/Jupyter%20Notebook-orange)](https://github.com/laminlabs/lamindb/blob/main/docs/tutorial.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage files & datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biology is measured in samples that generate data batches and you'll almost always start out with files.\n",
    "\n",
    "LaminDB helps you transform files into validated, queryable datasets.\n",
    "\n",
    "The tutorial has two parts:\n",
    "\n",
    "1. Register & access data: {doc}`/tutorial`\n",
    "2. Validate data: {doc}`/tutorial1`\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/BunYmHkyFLITlM5MYQci.svg\" width=\"450px\" style=\"background: transparent\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `pip install 'lamindb[aws,jupyter]'` and `lamin signup <email>` on the command line (more [info](/setup))."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the CLI, create a LaminDB instance with a directory `./mydata` for storing data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "!lamin init --storage ./mydata  # or \"s3://my-bucket\" or \"gs://my-bucket\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} What else can I configure during setup?\n",
    "\n",
    "1. Instead of the default SQLite database, use PostgreSQL: `--db postgresql://<user>:<pwd>@<hostname>:<port>/<dbname>`\n",
    "2. Instead of a default instance name derived from storage, provide a custom name: `--name myinstance`\n",
    "3. Beyond the core schema, use bionty and other schemas: `--schema bionty,custom1,template1`\n",
    "\n",
    "For more, see {doc}`/setup`.\n",
    "\n",
    ":::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track a data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lamindb as ln"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code that generates a batch of data is a transform ({class}`~lamindb.Transform`). It could be a pipeline, a notebook or an app upload.\n",
    "\n",
    "Let's track the notebook that's being run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.track()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling {func}`~lamindb.track`, the notebook is automatically linked as the source of all data that's about to be saved!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} What happened under the hood?\n",
    "\n",
    "1. Imported package versions were detected\n",
    "2. Notebook metadata was detected and stored in a {class}`~lamindb.Transform` record\n",
    "3. Run metadata was detected and stored in a {class}`~lamindb.Run` record\n",
    "\n",
    ":::\n",
    "\n",
    ":::{dropdown} How do I track a pipeline instead of a notebook?\n",
    "\n",
    "```python\n",
    "transform = ln.Transform(name=\"My pipeline\", version=\"1.2.0\")\n",
    "ln.track(transform)\n",
    "```\n",
    "\n",
    ":::\n",
    "\n",
    ":::{dropdown} Why should I care about tracking notebooks?\n",
    "\n",
    "If you can, avoid interactive notebooks: Anything that can be a deterministic pipeline, should be a pipeline.\n",
    "\n",
    "Just: much insight generated from biological data is driven by computational biologists _interacting_ with it.\n",
    "\n",
    "A notebook that's run a single time on specific data is not a pipeline: it's a (versioned) **document** that produced insight or some other form of data representation (with parallels to an ELN in the wetlab).\n",
    "\n",
    "Because humans are in the loop, most mistakes happen when using notebooks: {func}`~lamindb.track` helps avoiding some.\n",
    "\n",
    "(An early blog post on this is [here](https://lamin.ai/blog/2022/nbproject).)\n",
    "\n",
    ":::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll work with a toy dataset of image files and transform it into higher-level features for downstream analysis.\n",
    "\n",
    "(For other data types: see {doc}`docs:by-datatype`.)\n",
    "\n",
    "Consider 3 directories storing images & metadata of Iris flowers, generated in 3 subsequent studies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.File.view_tree(\"s3://lamindb-dev-datasets/iris_studies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to turn these files into a validated & queryable dataset that can be used alongside many other datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register a file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a {class}`~lamindb.File` object from one of the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = ln.File(\"s3://lamindb-dev-datasets/iris_studies/study0_raw_images/meta.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} What is lamindb's File class?\n",
    "\n",
    "It's a registry that manages search, queries, validation & access of files through metadata.\n",
    "\n",
    "Basic fields are:\n",
    "\n",
    "- `id`: a universal ID (serves as a primary key in the underlying SQL table of the instance)\n",
    "- `key`: an optional storage key, i.e., the relative path of the file in `storage`\n",
    "- `description`: an optional string description\n",
    "- `storage`: the storage location (the root, say, an S3 bucket or network location)\n",
    "- `suffix`: the file suffix\n",
    "- `size`: the file size in bytes\n",
    "- `hash`: a hash useful to check for integrity and collisions (is this file already stored?)\n",
    "- `hash_type`: the type of the hash (usually, an MD5 or SHA1 checksum)\n",
    "- `created_at`: time of creation\n",
    "- `updated_at`: time of last update\n",
    "\n",
    "Provenance-related fields are:\n",
    "\n",
    "- `created_by`: the {class}`~lamindb.User` who created the file\n",
    "- `transform`: the {class}`~lamindb.Transform` (pipeline, notebook, instrument, app) that was run\n",
    "- `run`: the {class}`~lamindb.Run` of the transform that created the file\n",
    "\n",
    "Access the path through a property:\n",
    "\n",
    "- `path`: the file path\n",
    "\n",
    "Access the underlying data:\n",
    "\n",
    "- `load()`: load the file to memory for formats like `.parquet`, `.zarr`, and `.h5ad`\n",
    "- `backed()`: stream/query the file from the cloud\n",
    "- `stage()`: a local path to a cached object\n",
    "- `replace()`: replace the content of the file\n",
    "\n",
    "For a full reference, see {class}`~lamindb.File`.\n",
    "\n",
    ":::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon `.save()`, file metadata is written to the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View data flow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we called {func}`~lamindb.track`, we know where the file came ({meth}`~lamindb.dev.Data.view_flow`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.view_flow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also directly access its linked {class}`~lamindb.Transform` & {class}`~lamindb.Run` records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(For a comprehensive example with data flow through app uploads, pipelines & notebooks of multiple data types, see {doc}`docs:project-flow`.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{attr}`~lamindb.File.path` gives you a filepath:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the file to a local cache, call {meth}`~lamindb.File.stage`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.stage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load a file into memory with a default loader, call {meth}`~lamindb.File.load`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = file.load(index_col=0)  # calls `pd.read_csv` and passes `index_col=0` to it\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the file is large, you'll likely want to query it via {meth}`~lamindb.File.backed`. For more on this, see: {doc}`data`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With {meth}`~lamindb.File.from_dir` we now register the entire directory of the first study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ln.File.from_dir(\"s3://lamindb-dev-datasets/iris_studies/study0_raw_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(We see that we already registered one of the files. Instead of creating a new file record, we'll get the existing one: see [idempotency](/faq/idempotency))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.save(files)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query & search files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can search files directly based on the {class}`~lamindb.File` registry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.File.search(\"meta\").head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also query & search the file by any metadata combination.\n",
    "\n",
    "For instance, look up a user with auto-complete from the {class}`~lamindb.User` registry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = ln.User.lookup()\n",
    "users.testuser1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the {class}`~lamindb.Transform` registry for a name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = ln.Transform.filter(\n",
    "    name__contains=\"files & datasets\"\n",
    ").one()  # get exactly one result\n",
    "transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} What does a double underscore mean?\n",
    "\n",
    "For any field, the double underscore defines a comparator, e.g.,\n",
    "\n",
    "* `name__icontains=\"Martha\"`: `name` contains `\"Martha\"` when ignoring case\n",
    "* `name__startswith=\"Martha\"`: `name` starts with `\"Martha`\n",
    "* `name__in=[\"Martha\", \"John\"]`: `name` is `\"John\"` or `\"Martha\"`\n",
    "\n",
    "For more info, see: {doc}`meta`.\n",
    "\n",
    ":::\n",
    "\n",
    "Use these results to filter the {class}`~lamindb.File` registry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.File.filter(\n",
    "    created_by=users.testuser1,\n",
    "    transform=transform,\n",
    "    suffix=\".jpg\",\n",
    ").df().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also query for directories using `key__startswith` (LaminDB treats directories like AWS S3, as the prefix of the storage `key`): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.File.filter(key__startswith=\"iris_studies/study0_raw_images/\").df().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "\n",
    "You can look up, filter & search any registry ({class}`~lamindb.dev.Registry`).\n",
    "\n",
    "You can chain {meth}`~lamindb.dev.Registry.filter` statements and {meth}`~lamindb.dev.QuerySet.search`: `ln.File.filter(suffix=\".jpg\").search(\"my image\")`\n",
    "\n",
    "An empty filter returns the entire registry: `ln.File.filter()`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more info, see: {doc}`meta`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an overview of what happened:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.view_flow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to version a file or transform, either provide the `version` parameter when creating it or create new versions through `is_new_version_of`.\n",
    "\n",
    "For instance:\n",
    "```\n",
    "new_file = ln.File(data, is_new_version_of=old_file)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there remaining questions about storing files? If so, see: {doc}`docs:faq/storage`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 50 image files together with their metadata annotations present a dataset. Let's track it as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ln.Dataset(\n",
    "    files, name=\"Iris study 1\", description=\"50 image files and metadata\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most functionality that you just learned about files - e.g., queries & provenance - also applies to {class}`~lamindb.Dataset`.\n",
    "\n",
    "The important difference is that a `Dataset` does not have a `key` field: it's an abstraction over storing data in one or several files or other storage backends.\n",
    "\n",
    "We'll learn more about dataasets in the next part of the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View changes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With {func}`~lamindb.view`, you can see the latest changes to the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.view()  # link tables in the database are not shown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you already know about 6 out of 10 LaminDB core classes! The two most central are:\n",
    "\n",
    "- {class}`~lamindb.File`: data batches\n",
    "- {class}`~lamindb.Dataset`: collections of data batches\n",
    "\n",
    "And the four registries related to provenance:\n",
    "\n",
    "- {class}`~lamindb.Transform`: transforms of files & datasets\n",
    "- {class}`~lamindb.Run`: runs of transforms\n",
    "- {class}`~lamindb.User`: users\n",
    "- {class}`~lamindb.Storage`: storage locations like S3/GCP buckets or local directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to validate data, label files & datasets and manage features, read on: {doc}`/tutorial1`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "nbproject": {
   "id": "NJvdsWWbJlZS",
   "parent": null,
   "pypackage": null,
   "time_init": "2023-03-09T13:30:29.239953+00:00",
   "user_handle": "testuser2",
   "user_id": "bKeW4T6E",
   "user_name": "Test User2",
   "version": "0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ae1fefc8646a06dd2e75004cd934adda7c5727b046986a772e3b44b0ffba9754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
