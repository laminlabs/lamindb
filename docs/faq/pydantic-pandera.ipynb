{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pydantic & Pandera vs. LaminDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doc explains conceptual differences between data validation with `pydantic`, `pandera`, and `LaminDB`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "!lamin init --storage test-pydantic-pandera --modules bionty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us work with a test dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pydantic\n",
    "import lamindb as ln\n",
    "import bionty as bt\n",
    "import pandera.pandas as pandera\n",
    "import pprint\n",
    "\n",
    "from typing import Literal, Any\n",
    "\n",
    "df = ln.examples.datasets.mini_immuno.get_dataset1()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Perturbation = Literal[\"DMSO\", \"IFNG\"]\n",
    "CellType = Literal[\"T cell\", \"B cell\"]\n",
    "OntologyID = Literal[\"EFO:0008913\"]\n",
    "\n",
    "\n",
    "class ImmunoSchema(pydantic.BaseModel):\n",
    "    perturbation: Perturbation\n",
    "    cell_type_by_model: CellType\n",
    "    cell_type_by_expert: CellType\n",
    "    assay_oid: OntologyID\n",
    "    concentration: str\n",
    "    treatment_time_h: int\n",
    "    donor: str | None\n",
    "\n",
    "    class Config:\n",
    "        title = \"My immuno schema\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandera_schema = pandera.DataFrameSchema(\n",
    "    {\n",
    "        \"perturbation\": pandera.Column(\n",
    "            str, checks=pandera.Check.isin([\"DMSO\", \"IFNG\"])\n",
    "        ),\n",
    "        \"cell_type_by_model\": pandera.Column(\n",
    "            str, checks=pandera.Check.isin([\"T cell\", \"B cell\"])\n",
    "        ),\n",
    "        \"cell_type_by_expert\": pandera.Column(\n",
    "            str, checks=pandera.Check.isin([\"T cell\", \"B cell\"])\n",
    "        ),\n",
    "        \"assay_oid\": pandera.Column(str, checks=pandera.Check.isin([\"EFO:0008913\"])),\n",
    "        \"concentration\": pandera.Column(str),\n",
    "        \"treatment_time_h\": pandera.Column(int),\n",
    "        \"donor\": pandera.Column(str, nullable=True),\n",
    "    },\n",
    "    name=\"My immuno schema\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LaminDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features & labels are defined on the level of the database instance.\n",
    "You can either define a schema with required (and optional) columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Record(name=\"DMSO\").save()\n",
    "ln.Record(name=\"IFNG\").save()\n",
    "\n",
    "# leverage ontologies through types ln.Record, bt.CellType, bt.ExperimentalFactor\n",
    "lamindb_schema = ln.Schema(\n",
    "    name=\"My immuno schema\",\n",
    "    features=[\n",
    "        ln.Feature(name=\"perturbation\", dtype=ln.Record).save(),\n",
    "        ln.Feature(name=\"cell_type_by_model\", dtype=bt.CellType).save(),\n",
    "        ln.Feature(name=\"cell_type_by_expert\", dtype=bt.CellType).save(),\n",
    "        ln.Feature(name=\"assay_oid\", dtype=bt.ExperimentalFactor.ontology_id).save(),\n",
    "        ln.Feature(name=\"concentration\", dtype=str).save(),\n",
    "        ln.Feature(name=\"treatment_time_h\", dtype=int).save(),\n",
    "        ln.Feature(name=\"donor\", dtype=str, nullable=True).save(),\n",
    "    ],\n",
    ").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or merely define a constraint on the feature identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamindb_schema_only_itype = ln.Schema(\n",
    "    name=\"Allow any valid features & labels\", itype=ln.Feature\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameValidationError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def validate_dataframe(df: pd.DataFrame, model: type[pydantic.BaseModel]):\n",
    "    errors = []\n",
    "\n",
    "    for i, row in enumerate(df.to_dict(orient=\"records\")):\n",
    "        try:\n",
    "            model(**row)\n",
    "        except pydantic.ValidationError as e:\n",
    "            errors.append(f\"row {i} failed validation: {e}\")\n",
    "\n",
    "    if errors:\n",
    "        error_message = \"\\n\".join(errors)\n",
    "        raise DataFrameValidationError(\n",
    "            f\"DataFrame validation failed with the following errors:\\n{error_message}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    validate_dataframe(df, ImmunoSchema)\n",
    "except DataFrameValidationError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix the validation error, we need to update the `Literal` and re-run the model definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Perturbation = Literal[\"DMSO\", \"IFNG\"]\n",
    "CellType = Literal[\n",
    "    \"T cell\", \"B cell\", \"CD8-positive, alpha-beta T cell\"  # <-- updated\n",
    "]\n",
    "OntologyID = Literal[\"EFO:0008913\"]\n",
    "\n",
    "\n",
    "class ImmunoSchema(pydantic.BaseModel):\n",
    "    perturbation: Perturbation\n",
    "    cell_type_by_model: CellType\n",
    "    cell_type_by_expert: CellType\n",
    "    assay_oid: OntologyID\n",
    "    concentration: str\n",
    "    treatment_time_h: int\n",
    "    donor: str | None\n",
    "\n",
    "    class Config:\n",
    "        title = \"My immuno schema\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_dataframe(df, ImmunoSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    pandera_schema.validate(df)\n",
    "except pandera.errors.SchemaError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LaminDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the term `\"CD8-positive, alpha-beta T cell\"` is part of the public `CellType` ontology, validation passes the first time.\n",
    "\n",
    "If validation had not passed, we could have resolved the issue simply by adding a new term to the `CellType` registry rather than editing the code.\n",
    "This also puts downstream data scientists into a position to update ontologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "curator = ln.curators.DataFrameCurator(df, lamindb_schema)\n",
    "curator.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the cell type validation based on? Let's inspect the `CellType` registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "bt.CellType.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `CellType` regsitry is hierachical as it contains the Cell Ontology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "bt.CellType.get(name=\"CD8-positive, alpha-beta T cell\").view_parents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of validation properties\n",
    "\n",
    "Importantly, LaminDB offers not only a `DataFrameCurator`, but also a `AnnDataCurator`, `MuDataCurator`, `SpatialDataCurator`, and `TiledbsomaCurator`.\n",
    "\n",
    "The below overview only concerns validating dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experience of data engineer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "property | `pydantic` | `pandera` | `lamindb`\n",
    "--- | --- | --- | ---\n",
    "define schema as code | yes, in form of a `pydantic.BaseModel` | yes, in form of a `pandera.DataFrameSchema` | yes, in form of a `lamindb.Schema`\n",
    "define schema as a set of constraints without the need of listing fields/columns/features; e.g. useful if validating 60k genes | no | no | yes\n",
    "update labels independent of code | not possible because labels are enums/literals | not possible because labels are hard-coded in `Check` | possible by adding new terms to a registry\n",
    "built-in validation from public ontologies | no | no | yes\n",
    "sync labels with ELN/LIMS registries without code change | no | no | yes\n",
    "can re-use fields/columns/features across schemas | limited via subclass | only in same Python session | yes because persisted in database\n",
    "schema modifications can invalidate previously validated datasets | yes | yes | no because LaminDB allows to query datasets that were validated with a schema version\n",
    "can use columnar organization of dataframe | no, need to iterate over potentially millions of rows | yes | yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experience of data consumer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "property | `pydantic` | `pandera` | `lamindb`\n",
    "--- | --- | --- | ---\n",
    "dataset is queryable / findable | no | no | yes, by querying for labels & features\n",
    "dataset is annotated | no | no | yes\n",
    "user knows what validation constraints were | no, because might not have access to code and doesn't know which code was run | no (same as pydantic) | yes, via `artifact.schema` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation & queryability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineer: annotate the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either use the `Curator` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "artifact = curator.save_artifact(key=\"our_datasets/dataset1.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't expect a need for Curator functionality for updating ontologies and standardization, you can also use the `Artifact` constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "artifact = ln.Artifact.from_dataframe(\n",
    "    df, key=\"our_datasets/dataset1.parquet\", schema=lamindb_schema\n",
    ").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer: see annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "artifact.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer: query the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-outut"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.filter(perturbation=\"IFNG\").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer: understand validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By accessing `artifact.schema`, the consumer can understand _how_ the dataset was validated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "artifact.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "artifact.schema.features.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested data with dynamic keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now examine another more complex example where data is nested with potentially arbitrary (dynamic) keys.\n",
    "The example is inspired by the [CELLxGENE schema](https://github.com/chanzuckerberg/single-cell-curation/blob/main/schema/6.0.0/schema.md#uns-dataset-metadata) where annotations are stored as dictionaries in the AnnData `.uns` slot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uns_dict = ln.examples.datasets.dict_cellxgene_uns()\n",
    "pprint.pprint(uns_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pydantic is primed to deal with nested data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Images(pydantic.BaseModel):\n",
    "    fullres: str\n",
    "    hires: str\n",
    "\n",
    "\n",
    "class Scalefactors(pydantic.BaseModel):\n",
    "    spot_diameter_fullres: float\n",
    "    tissue_hires_scalef: float\n",
    "\n",
    "\n",
    "class Library(pydantic.BaseModel):\n",
    "    images: Images\n",
    "    scalefactors: Scalefactors\n",
    "\n",
    "\n",
    "class Spatial(pydantic.BaseModel):\n",
    "    is_single: bool\n",
    "    model_config = {\"extra\": \"allow\"}\n",
    "\n",
    "    def __init__(self, **data):\n",
    "        libraries = {}\n",
    "        other_fields = {}\n",
    "\n",
    "        # store all libraries under a single key for validation\n",
    "        for key, value in data.items():\n",
    "            if key.startswith(\"library_\"):\n",
    "                libraries[key] = Library(**value)\n",
    "            else:\n",
    "                other_fields[key] = value\n",
    "\n",
    "        other_fields[\"libraries\"] = libraries\n",
    "        super().__init__(**other_fields)\n",
    "\n",
    "\n",
    "class SpatialDataSchema(pydantic.BaseModel):\n",
    "    organism_ontology_term_id: str\n",
    "    spatial: Spatial\n",
    "\n",
    "\n",
    "validated_data = SpatialDataSchema(**uns_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, pydantic either requires all dictionary keys to be known beforehand to construct the Model classes or workarounds to collect all keys for a single model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandera cannot validate dictionaries because it is designed for structured dataframe data.\n",
    "Therefore, we need to flatten the dictionary to transform it into a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _flatten_dict(d: dict[Any, Any], parent_key: str = \"\", sep: str = \"_\"):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(_flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dynamic_schema(flattened_data: dict[str, Any]):\n",
    "    schema_dict = {\n",
    "        \"organism_ontology_term_id\": pandera.Column(str),\n",
    "        \"spatial_is_single\": pandera.Column(bool),\n",
    "    }\n",
    "\n",
    "    for key in flattened_data.keys():\n",
    "        if key.startswith(\"spatial_library_\") and key.endswith(\"_images_fullres\"):\n",
    "            lib_prefix = key.replace(\"_images_fullres\", \"\")\n",
    "            schema_dict.update(\n",
    "                {\n",
    "                    f\"{lib_prefix}_images_fullres\": pandera.Column(str),\n",
    "                    f\"{lib_prefix}_images_hires\": pandera.Column(str),\n",
    "                    f\"{lib_prefix}_scalefactors_spot_diameter_fullres\": pandera.Column(\n",
    "                        float\n",
    "                    ),\n",
    "                    f\"{lib_prefix}_scalefactors_tissue_hires_scalef\": pandera.Column(\n",
    "                        float\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return pandera.DataFrameSchema(schema_dict)\n",
    "\n",
    "\n",
    "flattened = _flatten_dict(uns_dict)\n",
    "df = pd.DataFrame([flattened])\n",
    "spatial_schema = create_dynamic_schema(flattened)\n",
    "validated_df = spatial_schema.validate(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogously to pydantic, pandera does not have out of the box support for dynamically named keys.\n",
    "Therefore, it is necessary to dynamically construct a pydantic schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LaminDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, LaminDB currently requires constructing flattened dataframes to dynamically create features for the schema, which can then be used for validation with the DataFrameCurator.\n",
    "Future improvements are expected, including support for a dictionary-specific curator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "def create_dynamic_schema(flattened_data: dict[str, Any]) -> ln.Schema:\n",
    "    features = []\n",
    "\n",
    "    for key, value in flattened_data.items():\n",
    "        if key == \"organism_ontology_term_id\":\n",
    "            features.append(ln.Feature(name=key, dtype=bt.Organism.ontology_id).save())\n",
    "        elif isinstance(value, bool):\n",
    "            features.append(ln.Feature(name=key, dtype=bool).save())\n",
    "        elif isinstance(value, (int, float)):\n",
    "            features.append(ln.Feature(name=key, dtype=float).save())\n",
    "        else:\n",
    "            features.append(ln.Feature(name=key, dtype=str).save())\n",
    "\n",
    "    return ln.Schema(\n",
    "        name=\"Spatial data schema\", features=features, coerce_dtype=True\n",
    "    ).save()\n",
    "\n",
    "\n",
    "flattened = _flatten_dict(uns_dict)\n",
    "flattened_df = pd.DataFrame([flattened])\n",
    "spatial_schema = create_dynamic_schema(flattened)\n",
    "curator = ln.curators.DataFrameCurator(flattened_df, spatial_schema)\n",
    "curator.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Curators for scverse data structures allow for the specification of schema slots that access and validate dataframes in nested dictionary attributes like `.attrs` or `.uns`.\n",
    "These schema slots use colon-separated paths like `'attrs:sample'` or `'uns:spatial:images'` to target specific dataframes for validation.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lamindb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
