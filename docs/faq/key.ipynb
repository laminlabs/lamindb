{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does the key parameter do under the hood?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LaminDB is designed around associating biological metadata to files and datasets.\n",
    "This enables querying for them in storage by metadata and removes the requirement for semantic file and dataset names.\n",
    "\n",
    "Here, we will discuss trade-offs for using the `key` parameter, which allows for semantic keys, in various scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're simulating a file system with several nested folders and files.\n",
    "Such structures are resembled in, for example, the {doc}`docs:rxrx` guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def create_complex_biological_hierarchy(root_folder):\n",
    "    root_path = Path(root_folder)\n",
    "\n",
    "    if root_path.exists():\n",
    "        print(\"Folder structure already exists. Skipping...\")\n",
    "    else:\n",
    "        root_path.mkdir()\n",
    "\n",
    "        raw_folder = root_path / \"raw\"\n",
    "        preprocessed_folder = root_path / \"preprocessed\"\n",
    "        raw_folder.mkdir()\n",
    "        preprocessed_folder.mkdir()\n",
    "\n",
    "        for i in range(1, 5):\n",
    "            file_name = f\"raw_data_{i}.txt\"\n",
    "            with (raw_folder / file_name).open(\"w\") as f:\n",
    "                random_text = \"\".join(\n",
    "                    random.choice(string.ascii_letters) for _ in range(10)\n",
    "                )\n",
    "                f.write(random_text)\n",
    "\n",
    "        for i in range(1, 3):\n",
    "            dataset_folder = raw_folder / f\"Dataset_{i}\"\n",
    "            dataset_folder.mkdir()\n",
    "\n",
    "            for j in range(1, 5):\n",
    "                file_name = f\"raw_data_{j}.txt\"\n",
    "                with (dataset_folder / file_name).open(\"w\") as f:\n",
    "                    random_text = \"\".join(\n",
    "                        random.choice(string.ascii_letters) for _ in range(10)\n",
    "                    )\n",
    "                    f.write(random_text)\n",
    "\n",
    "        for i in range(1, 5):\n",
    "            file_name = f\"result_{i}.txt\"\n",
    "            with (preprocessed_folder / file_name).open(\"w\") as f:\n",
    "                random_text = \"\".join(\n",
    "                    random.choice(string.ascii_letters) for _ in range(10)\n",
    "                )\n",
    "                f.write(random_text)\n",
    "\n",
    "\n",
    "root_folder = \"complex_biological_project\"\n",
    "create_complex_biological_hierarchy(root_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!lamin init --storage ./key-eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lamindb as ln\n",
    "\n",
    "\n",
    "ln.settings.verbosity = \"hint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.UPath.view_tree(\"complex_biological_project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.track()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing files using `Storage`, `File`, and `Dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lamin has three storage classes that manage different types of in-memory and on-disk objects:\n",
    "\n",
    "1. {class}`~lamindb.Storage`: Manages the default storage root that can be either local or in the cloud. For more details we refer to {doc}`docs:faq/storage`.\n",
    "2. {class}`~lamindb.File`: Manages data batches with an optional `key` that acts as a relative path within the current default storage root (see {class}`~lamindb.Storage`). An example is a single h5 file.\n",
    "3. {class}`~lamindb.Dataset`: Manages a collection of data batches with an optional `key` that acts as a relative path within the current default storage root (see {class}`~lamindb.Storage`). An example is a collection of h5 files.\n",
    "\n",
    "For more details we refer to {doc}`docs:tutorial`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current storage root is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.settings.storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Lamin uses virtual `keys` that are only reflected in the database but not in storage.\n",
    "It is possible to turn this behavior off by setting `ln.settings.file_use_virtual_keys = False`.\n",
    "Generally, we discourage disabling this setting manually. For more details we refer to {doc}`docs:faq/storage`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.settings.file_use_virtual_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create `File` objects with and without semantic keys using `key` and also save them as `Datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_no_key_1 = ln.File(\"complex_biological_project/raw/raw_data_1.txt\")\n",
    "file_no_key_2 = ln.File(\"complex_biological_project/raw/raw_data_2.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logging suggests that the files will be saved to our current default storage with auto generated storage keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_no_key_1.save()\n",
    "file_no_key_2.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_key_3 = ln.File(\n",
    "    \"complex_biological_project/raw/raw_data_3.txt\", key=\"raw/raw_data_3.txt\"\n",
    ")\n",
    "file_key_4 = ln.File(\n",
    "    \"complex_biological_project/raw/raw_data_4.txt\", key=\"raw/raw_data_4.txt\"\n",
    ")\n",
    "file_key_3.save()\n",
    "file_key_4.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Files` with keys are not stored in different locations because of the usage of `virtual keys`.\n",
    "However, they are still semantically queryable by `key`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.File.filter(key__contains=\"raw\").df().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dataset` does not have a `key` parameter because it does not store any additional data in `Storage`.\n",
    "In contrast, it has a `name` parameter that serves as a semantic identifier of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_1 = ln.Dataset(data=[file_no_key_1, file_no_key_2], name=\"no key collection\")\n",
    "ds_2 = ln.Dataset(data=[file_key_3, file_key_4], name=\"sample collection\")\n",
    "ds_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages and disadvantages of semantic keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic keys have several advantages and disadvantages that we will discuss and demonstrate in the remaining notebook:\n",
    "\n",
    "### Advantages:\n",
    "\n",
    "- Simple: It can be easier to refer to specific datasets in conversations\n",
    "- Familiarity: Most people are familiar with the concept of semantic names\n",
    "\n",
    "### Disadvantages\n",
    "\n",
    "- Length: Semantic names can be long with limited aesthetic appeal\n",
    "- Inconsistency: Lack of naming conventions can lead to confusion\n",
    "- Limited metadata: Semantic keys can contain some, but usually not all metadata\n",
    "- Inefficiency: Writing lengthy semantic names is a repetitive process and can be time-consuming\n",
    "- Ambiguity: Overly descriptive file names may introduce ambiguity and redundancy\n",
    "- Clashes: Several people may attempt to use the same semantic key. They are not unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming `Files` that have associated keys can be done on several levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A file can be locally moved or renamed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_key_3.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_file = file_key_3.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir complex_biological_project/moved_files\n",
    "!mv complex_biological_project/raw/raw_data_3.txt complex_biological_project/moved_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_key_3.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After moving the file locally, the storage location (the path) has not changed and the file can still be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_3 = file_key_3.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same applies to the `key` which has not changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_key_3.key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides moving the file in storage, the `key` can also be renamed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_key_4.key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_key_4.key = \"bad_samples/sample_data_4.txt\"\n",
    "file_key_4.key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the usage of virtual `keys`, modifying the key does not change the storage location and the file stays accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_key_4.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_4 = file_key_4.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying the `path` attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, modifying the `path` directly is not allowed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    file_key_4.path = f\"{ln.settings.storage}/here_now/sample_data_4.txt\"\n",
    "except AttributeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clashing semantic keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic keys should not clash. Let's attempt to use the same semantic key twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file_key_3.key)\n",
    "print(file_key_4.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_key_4.key = \"raw/raw_data_3.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file_key_3.key)\n",
    "print(file_key_4.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When filtering for this semantic key it is now unclear to which file we were referring to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.File.filter(key__icontains=\"sample_data_3\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When querying by `key` LaminDB cannot resolve which file we actually wanted.\n",
    "In fact, we only get a single hit which does not paint a complete picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file_key_3.uid)\n",
    "print(file_key_4.uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both files still exist though with unique `uids` that can be used to get access to them.\n",
    "Most importantly though, saving these files to the database will result in an `IntegrityError` to prevent this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    file_key_3.save()\n",
    "    file_key_4.save()\n",
    "except Exception as e:\n",
    "    print(\n",
    "        \"It is not possible to save files to the same key. This results in an Integrity\"\n",
    "        \" Error!\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We refer to {doc}`docs:faq/idempotency` for more detailed explanations of behavior when attempting to save files multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common use-case of `keys` are file hierarchies.\n",
    "It can be useful to resemble the file structure in \"complex_biological_project\" from above also in LaminDB to allow for queries for files that were stored in specific folders.\n",
    "Common examples of this are folders specifying different processing stages such as `raw`, `preprocessed`, or `annotated`.\n",
    "\n",
    "Note that this use-case may also be overlapping with `Dataset` which also allows for grouping `Files`.\n",
    "However, `Dataset` cannot model hierarchical groupings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for root, _, files in os.walk(\"complex_biological_project/raw\"):\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(root, filename)\n",
    "        key_path = file_path.removeprefix(\"complex_biological_project\")\n",
    "        ln_file = ln.File(file_path, key=key_path)\n",
    "        ln_file.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.File.filter(key__startswith=\"raw\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, it would have been possible to create a `Dataset` with a corresponding name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_paths = []\n",
    "for root, _, files in os.walk(\"complex_biological_project/raw\"):\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(root, filename)\n",
    "        all_data_paths.append(file_path)\n",
    "\n",
    "all_data_files = []\n",
    "for path in all_data_paths:\n",
    "    all_data_files.append(ln.File(path))\n",
    "\n",
    "data_ds = ln.Dataset(all_data_files, name=\"data\")\n",
    "data_ds.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.Dataset.filter(name__icontains=\"data\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach will likely lead to clashes. Alternatively, `Ulabels` can be added to `Files` to resemble hierarchies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ulabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, _, files in os.walk(\"complex_biological_project/raw\"):\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(root, filename)\n",
    "        key_path = file_path.removeprefix(\"complex_biological_project\")\n",
    "        ln_file = ln.File(file_path, key=key_path)\n",
    "        ln_file.save()\n",
    "\n",
    "        data_label = ln.ULabel(name=\"data\")\n",
    "        data_label.save()\n",
    "        ln_file.ulabels.add(data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ln.ULabel.lookup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.File.filter(ulabels__in=[labels.data]).df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, `Ulabels` are too versatile for such an approach and clashes are also to be expected here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the chance of clashes for the aforementioned approaches being rather high, we generally recommend not to store hierarchical data with solely semantic keys.\n",
    "Biological metadata makes `Files` and `Datasets` unambiguous and easily queryable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legacy data and multiple storage roots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LaminDB can ingest legacy data that already had a structure in their storage.\n",
    "In such cases, it disables `file_use_virtual_keys` and the files are ingested with their actual storage location.\n",
    "It might be therefore be possible that `Files` stored in different storage roots may be associated with a single `Dataset`.\n",
    "To simulate this, we are disabling `file_use_virtual_keys` and ingest files stored in a different path (the \"legacy data\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.settings.file_use_virtual_keys = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, _, files in os.walk(\"complex_biological_project/preprocessed\"):\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(root, filename)\n",
    "        key_path = file_path.removeprefix(\"complex_biological_project\")\n",
    "\n",
    "        print(file_path)\n",
    "        print()\n",
    "\n",
    "        ln_file = ln.File(file_path, key=f\"./{key_path}\")\n",
    "        ln_file.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.File.filter().df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_from_raw = ln.File.filter(key__icontains=\"Dataset_2/raw_data_1\").first()\n",
    "file_from_preprocessed = ln.File.filter(key__icontains=\"preprocessed/result_1\").first()\n",
    "\n",
    "print(file_from_raw.path)\n",
    "print(file_from_preprocessed.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ln.Dataset(\n",
    "    [file_from_raw, file_from_preprocessed], name=\"raw_and_processed_dataset_2\"\n",
    ")\n",
    "ds.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.files.df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.settings.file_use_virtual_keys = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = ln.dev.datasets.dir_scrnaseq_cellranger(\"sample_001\")\n",
    "ln.UPath.view_tree(dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to create `File` objects from folders: {func}`~lamindb.File.from_dir` and {class}`~lamindb.Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellranger_raw_file = ln.File.from_dir(\"sample_001/raw_feature_bc_matrix/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in cellranger_raw_file:\n",
    "    file.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellranger_raw_ds = ln.Dataset(\n",
    "    \"sample_001/raw_feature_bc_matrix/\", name=\"cellranger raw\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellranger_raw_ds.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.File.filter(key__icontains=\"raw_feature_bc_matrix\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.File.filter(key__icontains=\"raw_feature_bc_matrix/matrix.mtx.gz\").one().path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_paths = [\n",
    "    file.stage() for file in ln.Dataset.filter(name=\"cellranger raw\").one().files.all()\n",
    "]\n",
    "# We expect the input_paths to be empty\n",
    "input_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `File.from_dir` creates explicit `File` objects with the default constructor, the `Dataset` constructor only returns a `Dataset` without any `File` records.\n",
    "The latter behavior is particularly useful when only a reference to a dataset is necessary and not to particular files.\n",
    "This saves a lot of transactions for particularly large datasets with a lot of files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Messing with the storage root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.settings.storage.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED TO MOVE TO POSTGRES OR SOMETHING\n",
    "ln.settings.storage = \"/filtered\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.settings.storage.view_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the storage root\n",
    "\n",
    "Question: Are things going to work well when setting the current storage to `ln.settings.storage = \"s3://theislab/raw\"`?\n",
    "Basically if people are using a semantic key, can we change the storage root that uses the key prefix to store the data there?\n",
    "\n",
    "Answer: I currently cannot change the storage root of the S3 based storage because I'm running a sqlite instance. I'd have to use LaminData or so.\n",
    "Generally this should work. However, we discourage people from messing with the storage location anyway and only to trust the `virtual keys`.\n",
    "There should not be a use-case for this with a single exception: People uploaded legacy data to Lamin, and they're reusing the storage for a different application where they also need to preserve the structure in the future. In such cases, `file_use_virtual_keys` should still be switched off even though we considered not exposing it anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The rxrx1 use-case\n",
    "\n",
    "Question: Does the rxrx1 use-case work well with our current `key` design?\n",
    "\n",
    "Answer: The rxrx1 use-case currently has an immutable parquet file with metadata associated with the `Dataset`.\n",
    "Since we did not register the `File` objects themselves, we have to query for the files and their paths through the parquet file.\n",
    "This requires the paths to be stable remote URLs that are kept sync with the metadata parquet `File`.\n",
    "https://github.com/laminlabs/rxrx-lamin/blob/main/docs/notebooks/02-rxrx1.ipynb describes the curation for the images.\n",
    "Here, a `Dataset` is created without any `File` objects.\n",
    "The `Dataset` does not have `key`, solely `File` objects, which are not created here.\n",
    "Any hierarchy that is resembled in the `paths` and `path` (why 2?) columns of the metadata DataFrame is not reflected in `Storage` (via `key`) due to the lack of `Files`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the entire doc pretty much only using virtual keys\n",
    "\n",
    "Question: Another overarching remark concerns that the entire doc does in fact only use virtual keys, and no real storage keys.\n",
    "\n",
    "Answer: Yup, which is the default and we discussed removing the option to changing that.\n",
    "Only legacy data may be using real storage keys."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lamindb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "nbproject": {
   "id": "WIwaNDvlEkwS",
   "parent": null,
   "pypackage": null,
   "time_init": "2023-10-30T14:51:12.021579+00:00",
   "user_handle": null,
   "user_id": null,
   "user_name": null,
   "version": "0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
