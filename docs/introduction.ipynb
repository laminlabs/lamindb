{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "```{include} ../README.md\n",
    ":start-line: 6\n",
    ":end-line: -4\n",
    "```\n",
    "\n",
    ":::{dropdown} LaminDB features\n",
    "\n",
    "```{include} features-lamindb.md\n",
    "```\n",
    ":::\n",
    "\n",
    "LaminHub is a data collaboration hub built on LaminDB similar to how GitHub is built on git.\n",
    "\n",
    ":::{dropdown} LaminHub features\n",
    "\n",
    "```{include} features-laminhub.md\n",
    "```\n",
    ":::\n",
    "\n",
    "LaminHub is free for public data. Enterprise features, support, integration tests & wetlab plug-ins hosted in your or our infrastructure are available on a [paid plan](https://lamin.ai/pricing): please [reach out](https://lamin.ai/contact)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart\n",
    "\n",
    "```{warning}\n",
    "\n",
    "Public beta: Close to having converged a stable API, but some breaking changes might still occur.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup LaminDB\n",
    "\n",
    "1. Install the `lamindb` Python package:\n",
    "    ```shell\n",
    "    pip install 'lamindb[jupyter,bionty]'\n",
    "    ```\n",
    "2. [Sign up](https://lamin.ai/signup) for a free account (see more [info](https://lamin.ai/docs/setup)) and copy the API key.\n",
    "3. Log in on the command line:\n",
    "    ```shell\n",
    "    lamin login <email> --key <API-key>\n",
    "    ```\n",
    "\n",
    "You can now init LaminDB instances like you init git repositories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "!lamin init --schema bionty --storage ./lamin-intro  # or s3://my-bucket, gs://my-bucket as default storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we passed `--schema bionty`, this instance mounted plug-in {mod}`lnschema_bionty`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lamindb as ln\n",
    "import pandas as pd\n",
    "\n",
    "# track data flow\n",
    "ln.track()  # in a script or pipeline, pass a Transform record\n",
    "\n",
    "# access a batch of data\n",
    "df = pd.DataFrame(\n",
    "    {\"CD8\": [1, 2, 3], \"CD45\": [3, 4, 5], \"perturbation\": [\"DMSO\", \"IFNG\", \"DMSO\"]},\n",
    "    index=[\"measurement1\", \"measurement2\", \"measurement3\"],\n",
    ")\n",
    "\n",
    "# create a dataset (versioning is optional)\n",
    "dataset = ln.Dataset(df, name=\"Immune phenotyping\", version=\"1\")\n",
    "# register dataset\n",
    "dataset.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# search a dataset\n",
    "ln.Dataset.search(\"immune\")\n",
    "\n",
    "# query a dataset\n",
    "dataset = ln.Dataset.filter(name__contains=\"phenotyping\").first()\n",
    "\n",
    "# view data flow\n",
    "dataset.view_flow()\n",
    "\n",
    "# describe metadata\n",
    "dataset.describe()\n",
    "\n",
    "# load the dataset\n",
    "df = dataset.load()\n",
    "\n",
    "# access an underlying parquet file\n",
    "dataset.file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define features & labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define features through their names and types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_types = [(\"CD8\", \"number\"), (\"CD45\", \"number\"), (\"perturbation\", \"category\")]\n",
    "features = [ln.Feature(name=name, type=type) for (name, type) in names_types]\n",
    "ln.save(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define perturbation labels _schema-less_ using the {class}`~lamindb.ULabel` registry, a universal label ontology:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbations = [\n",
    "    ln.ULabel(name=perturbation) for perturbation in df.perturbation.unique()\n",
    "]\n",
    "\n",
    "is_perturbation = ln.ULabel(name=\"is_perturbation\")\n",
    "is_perturbation.save()\n",
    "\n",
    "for perturbation in perturbations:\n",
    "    perturbation.save()\n",
    "    perturbation.parents.add(is_perturbation)\n",
    "\n",
    "is_perturbation.view_parents(with_children=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate & annotate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataset with validated and linked features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create dataset & validate features\n",
    "dataset = ln.Dataset.from_df(df, name=\"Immune phenotyping 1\")\n",
    "# register dataset & link validated features\n",
    "dataset.save()\n",
    "\n",
    "dataset.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Warnings informed us that there are already a dataset and an underlying parquet file with matching hashes in storage; they are returned instead of duplicated.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotate with perturbation labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an object to auto-complete features\n",
    "features = ln.Feature.lookup()\n",
    "\n",
    "# annotate with a label (optionally pass the corresponding feature)\n",
    "dataset.labels.add(perturbations, feature=features.perturbation)\n",
    "\n",
    "dataset.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we indicated the corresponding feature for the perturbation labels, we'll also see the labels in the linked features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query for annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulabels = ln.ULabel.lookup()\n",
    "\n",
    "# all feature sets containing CD45\n",
    "panels_with_cd45 = ln.FeatureSet.filter(features=features.cd45).all()\n",
    "\n",
    "# all datasets measuring CD45\n",
    "display(ln.Dataset.filter(feature_sets__in=panels_with_cd45).df())\n",
    "\n",
    "# get exactly one query result of type Dataset\n",
    "dataset = ln.Dataset.filter(\n",
    "    feature_sets__in=panels_with_cd45, ulabels=ulabels.ifng\n",
    ").one()\n",
    "\n",
    "# delete the dataset including the underlying file\n",
    "dataset.delete(storage=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use biological types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the generic registries {class}`~lamindb.Feature` and {class}`~lamindb.ULabel` will get you pretty far.\n",
    "\n",
    "But if you use an entity many times, you typically want a dedicated registry, which you can use to type your code & as an interface for public ontologies.\n",
    "\n",
    "Let's do this for {class}`~lnschema_bionty.CellMarker` from plug-in {mod}`lnschema_bionty`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lnschema_bionty as lb\n",
    "\n",
    "# set a global species for multi-species registries\n",
    "lb.settings.species = \"human\"\n",
    "\n",
    "# create cell marker records from the public ontology\n",
    "cell_markers = [lb.CellMarker.from_bionty(name=name) for name in [\"CD8\", \"CD45\"]]\n",
    "ln.save(cell_markers)\n",
    "\n",
    "lb.CellMarker.filter().df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we now model cell markers explicitly, the features in our dataset have two types: data (the numerical expression measurements) and metadata (the categorical perturbation labels).\n",
    "\n",
    "The simplest data structure in Python to account for different types of features is [AnnData](https://github.com/scverse/anndata). Let's use it to store our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "\n",
    "# stratify features by cell markers vs metadata\n",
    "adata = ad.AnnData(df.loc[:, [\"CD8\", \"CD45\"]], obs=df.loc[:, [\"perturbation\"]])\n",
    "\n",
    "# create dataset & validate features\n",
    "dataset = ln.Dataset.from_anndata(\n",
    "    adata, name=\"Immune phenotyping\", field=lb.CellMarker.name\n",
    ")\n",
    "# register dataset & link validated features\n",
    "dataset.save()\n",
    "\n",
    "# annotate with labels\n",
    "dataset.labels.add(perturbations, feature=features.perturbation)\n",
    "\n",
    "dataset.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query for a panel of cell markers & the linked datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# an object to auto-complete cell markers\n",
    "cell_markers = lb.CellMarker.lookup()\n",
    "\n",
    "# all cell marker panel containing CD45\n",
    "panels_with_cd45 = ln.FeatureSet.filter(cell_markers=cell_markers.cd45).all()\n",
    "\n",
    "# all datasets measuring CD45\n",
    "ln.Dataset.filter(feature_sets__in=panels_with_cd45).df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Experimental Factor Ontology to link a validated label for the readout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# search the public ontology from the bionty store\n",
    "lb.ExperimentalFactor.bionty().search(\"facs\").head(2)\n",
    "\n",
    "# create a record for facs\n",
    "facs = lb.ExperimentalFactor.from_bionty(ontology_id=\"EFO:0009108\")\n",
    "facs.save()\n",
    "\n",
    "# label with an inhouse assay\n",
    "immune_assay1 = lb.ExperimentalFactor(name=\"Immune phenotyping assay 1\")\n",
    "immune_assay1.save()\n",
    "\n",
    "dataset.experimental_factors.add(facs, immune_assay1)\n",
    "\n",
    "# create a tissue from a public ontology\n",
    "bone_marrow = lb.Tissue.from_bionty(name=\"bone marrow\")\n",
    "bone_marrow.save()\n",
    "\n",
    "dataset.tissues.add(bone_marrow)\n",
    "\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append a new batch of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we now run a pipeline in which we access a new batch of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = ln.Transform(name=\".fcs file ingestion\", type=\"pipeline\", version=\"1\")\n",
    "ln.track(transform)\n",
    "\n",
    "# access a new batch of data with a different schema\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"CD8\": [2, 3, 3],\n",
    "        \"CD45\": [3, 4, 5],\n",
    "        \"CD38\": [4, 2, 3],\n",
    "        \"perturbation\": [\"IL2\", \"IL2\", \"IL2\"],\n",
    "        \"concentration\": [0.1, 0.2, 0.3],\n",
    "    },\n",
    "    index=[\"measurement4\", \"measurement5\", \"measurement6\"],\n",
    ")\n",
    "adata = ad.AnnData(\n",
    "    df.loc[:, [\"CD8\", \"CD45\", \"CD38\"]], obs=df.loc[:, [\"perturbation\", \"concentration\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `\"CD38\"` and `\"concentration\"` are not yet part of the {class}`~lamindb.Feature` registry, they don't yet validate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = ln.File.from_anndata(adata, description=\"Batch 2\", field=lb.CellMarker.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add them to the registries and re-create the file - now everything passes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb.CellMarker.from_bionty(name=\"CD38\").save()\n",
    "ln.Feature(name=\"concentration\", type=\"number\").save()\n",
    "file = ln.File.from_anndata(\n",
    "    adata, description=\"Immune phenotyping batch 2\", field=lb.CellMarker.name\n",
    ")\n",
    "file.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new version of the dataset by linking both batches in a \"sharded dataset\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_v2 = ln.Dataset([file, dataset.file], is_new_version_of=dataset)\n",
    "dataset_v2.describe()\n",
    "dataset_v2.save()\n",
    "dataset_v2.view_flow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load the entire dataset into memory as if it was one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_v2.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or iterate over its files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_v2.files.df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More examples\n",
    "\n",
    "### Understand data flow\n",
    "\n",
    "View the sequence of data transformations ({class}`~lamindb.Transform`) in a project (from [here](docs:project-flow), based on [Schmidt _et al._, 2022](https://pubmed.ncbi.nlm.nih.gov/35113687/)):\n",
    "\n",
    "```python\n",
    "transform.view_parents()\n",
    "```\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/b0geN1HDHXlORqMOOPay.svg\" width=\"400\">\n",
    "\n",
    "Or, the generating flow of a file or dataset:\n",
    "\n",
    "```python\n",
    "file.view_flow()\n",
    "```\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/KQmzmmLOeBN0C8Ykitjn.svg\" width=\"800\">\n",
    "\n",
    "\n",
    "Both figures are based on mere calls to `ln.track()` in notebooks, pipelines & app.\n",
    "\n",
    "\n",
    "### Manage biological registries\n",
    "\n",
    "Create a cell type registry from public knowledge and add a new cell state (from [here](bio-registries)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import lnschema_bionty as lb\n",
    "\n",
    "# create an ontology-coupled cell type record and save it\n",
    "lb.CellType.from_bionty(name=\"neuron\").save()\n",
    "\n",
    "# create a record to track a new cell state\n",
    "new_cell_state = lb.CellType(name=\"my neuron cell state\", description=\"explains X\")\n",
    "new_cell_state.save()\n",
    "\n",
    "# express that it's a neuron state\n",
    "cell_types = lb.CellType.lookup()\n",
    "new_cell_state.parents.add(cell_types.neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view ontological hierarchy\n",
    "new_cell_state.view_parents(distance=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leverage a mesh of instances\n",
    "\n",
    "LaminDB is a distributed system like git. Similar to cloning a repository, collaborators can load your instance on the command-line using:\n",
    "\n",
    "```shell\n",
    "lamin load myhandle/myinstance\n",
    "```\n",
    "\n",
    "If you run `lamin save <notebook_path>`, you will save the notebook to your default storage location.\n",
    "\n",
    "You can explore the notebook report corresponding to the quickstart [here](https://lamin.ai/laminlabs/lamindata/record/core/Transform?id=Hc5AXzibjGg1z8) in LaminHub.\n",
    "\n",
    "### Manage custom schemas\n",
    "\n",
    "LaminDB can be customized & extended with schema & app plug-ins building on the [Django](https://github.com/django/django) ecosystem. Examples are\n",
    "\n",
    "- [lnschema_bionty](lnschema_bionty): Registries for basic biological entities, coupled to public ontologies.\n",
    "- [lnschema_lamin1](https://github.com/laminlabs/lnschema-lamin1): Exemplary custom schema to manage samples, treatments, etc. \n",
    "\n",
    "If you'd like to create your own schema or app:\n",
    "\n",
    "1. Create a git repository with registries similar to [lnschema_lamin1](https://github.com/laminlabs/lnschema-lamin1)\n",
    "2. Create & deploy migrations via `lamin migrate create` and `lamin migrate deploy`\n",
    "\n",
    "It's fastest if we do this for you based on our templates within an enterprise plan.\n",
    "\n",
    "## Design\n",
    "\n",
    "### Why?\n",
    "\n",
    "We wrote a [blog post](https://lamin.ai/blog/2022/problems) about the key problems Lamin tries to solve when starting to work on it.\n",
    "\n",
    "### Schema & API\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/XoTQFCmmj2uU4d2xyj9t.png\" width=\"350px\" style=\"background: transparent\" align=\"right\">\n",
    "\n",
    "LaminDB provides a SQL schema for common entities: {class}`~lamindb.File`, {class}`~lamindb.Dataset`, {class}`~lamindb.Transform`, {class}`~lamindb.Feature`, {class}`~lamindb.ULabel` etc. - see the [API reference](reference) or the [source code](https://github.com/laminlabs/lnschema-core/blob/main/lnschema_core/models.py).\n",
    "\n",
    "The core schema is extendable through plug ins (see blue vs. red entities in **graphic**), e.g., with basic biological ({class}`~lnschema_bionty.Gene`, {class}`~lnschema_bionty.Protein`, {class}`~lnschema_bionty.CellLine`, etc.) & operational entities (`Biosample`, `Techsample`, `Treatment`, etc.).\n",
    "\n",
    "```{dropdown} What is the schema language?\n",
    "\n",
    "Data models are defined in Python using the Django ORM. Django translates them to SQL tables.\n",
    "\n",
    "[Django](https://github.com/django/django) is one of the most-used & highly-starred projects on GitHub (~1M dependents, ~73k stars) and has been robustly maintained for 15 years.\n",
    "\n",
    "In the first year, LaminDB used SQLModel/SQLAlchemy -- we might bring back compatibility.\n",
    "\n",
    "```\n",
    "\n",
    "On top of the schema, LaminDB is a Python API that abstracts over storage & database access, data transformations, and (biological) ontologies.\n",
    "\n",
    "The code for this is open-source & accessible through the dependencies & repositories listed below.\n",
    " \n",
    "### Dependencies\n",
    "\n",
    "- Data is stored in a platform-independent way: \n",
    "    - location → local, on AWS S3 or GCP Storage, accessed through `fsspec`\n",
    "    - format → blob-like files or queryable formats like parquet, zarr, HDF5, TileDB, ...\n",
    "- Metadata is stored in SQL: current backends are SQLite (small teams) and Postgres (any team size).\n",
    "- Django ORM for schema management & metadata queries.\n",
    "- Biological knowledge sources & ontologies: see [Bionty](https://lamin.ai/docs/bionty).\n",
    "\n",
    "For more details, see the [pyproject.toml](https://github.com/laminlabs/lamindb/blob/main/pyproject.toml) file in lamindb & the linked repositories below.\n",
    "\n",
    "### Repositories\n",
    "\n",
    "LaminDB and its plug-ins consist in open-source Python libraries & publicly hosted metadata assets:\n",
    "\n",
    "- [lamindb](https://github.com/laminlabs/lamindb): Core API, which builds on the [core schema](https://github.com/laminlabs/lnschema-core).\n",
    "- [lnschema-bionty](https://github.com/laminlabs/lnschema-bionty): Registries for basic biological entities, coupled to public ontologies.\n",
    "- [lnschema-lamin1](https://github.com/laminlabs/lnschema-lamin1): Exemplary custom schema to manage samples, treatments, etc.\n",
    "- [lamindb-setup](https://github.com/laminlabs/lamindb-setup): Setup & configure LaminDB, client for LaminHub.\n",
    "- [bionty](https://github.com/laminlabs/bionty): Accessor for public biological ontologies.\n",
    "- [nbproject](https://github.com/laminlabs/nbproject): Metadata parser for Jupyter notebooks.\n",
    "- [lamin-utils](https://github.com/laminlabs/lamin-utils): Generic utilities, e.g., a logger.\n",
    "- [readfcs](https://github.com/laminlabs/readfcs): FCS file reader.\n",
    "<!-- [bionty-assets](https://github.com/laminlabs/bionty-assets): Hosted assets of parsed public biological ontologies. -->\n",
    "\n",
    "LaminHub is not open-sourced, and neither are plug-ins that model lab operations.\n",
    "\n",
    "\n",
    "### Assumptions & principles\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/BunYmHkyFLITlM5MYQci.svg\" width=\"350px\" style=\"background: transparent\" align=\"right\">\n",
    "\n",
    "1. Data is generated by instruments that process physical samples: it comes in batches stored as immutable files.\n",
    "2. Files are transformed into more useful data representations, e.g.:\n",
    "   - Summary statistics, e.g., count matrices for fastq files\n",
    "   - Arrays of non-array-like input data (e.g., images)\n",
    "   - Higher-level embeddings for lower-level array, text or graph representations\n",
    "   - Concatenated arrays for large-scale atlas-like datasets\n",
    "3. Semantics of high-level embeddings (\"inflammatory\", \"lipophile\") are anchored in experimental metadata and knowledge (ontologies)\n",
    "4. Experimental metadata is another ontology type\n",
    "5. Experiments measure features ({class}`~lamindb.Feature`, {class}`~lnschema_bionty.CellMarker`, ...)\n",
    "6. Samples are annotated by labels ({class}`~lamindb.ULabel`, {class}`~lnschema_bionty.CellLine`, ...)\n",
    "7. Learning and data warehousing both iterate transformations (see **graphic**, {class}`~lamindb.Transform`)\n",
    "8. Basic biological entities should have the same meaning to anyone and across any data platform\n",
    "9. Schema migrations should be easy\n",
    "\n",
    "### Influences\n",
    "\n",
    "LaminDB was influenced by many other projects, see {doc}`docs:influences`.\n",
    "\n",
    "## Notebooks\n",
    "\n",
    "- Find all guide notebooks [here](https://github.com/laminlabs/lamindb/tree/main/docs/guide).\n",
    "- You can run these notebooks in hosted versions of JupyterLab, e.g., [Saturn Cloud](https://github.com/laminlabs/run-lamin-on-saturn), Google Vertex AI, Google Colab, and others.\n",
    "- Jupyter Lab & Notebook offer a fully interactive experience, VS Code & others require using the CLI to track notebooks: `lamin track my-notebook.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!lamin delete --force lamin-intro"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "nbproject": {
   "id": "FPnfDtJz8qbE",
   "parent": null,
   "pypackage": null,
   "time_init": "2023-08-29T19:04:20.821821+00:00",
   "user_handle": "falexwolf",
   "user_id": "FBa7SHjn",
   "user_name": "Alex Wolf",
   "version": "0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
