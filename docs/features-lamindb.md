**Why?**

In many organizations, fragmented object stores, SQL databases & ELN/LIMS systems pile up non-findable, inaccessible, hard-to-integrate & non-backtracable data.

This also holds for the derived analytical insights, which makes it hard to optimize learning & decision-making across team & ML models.

LaminDB attempts to provide a unified framework that addresses the [key problems](https://lamin.ai/blog/2022/problems) underlying this tendency.

**What?**

- Unified API to manage data in storage & metadata in SQL database
  - access: {class}`~lamindb.dev.Registry.filter`, {class}`~lamindb.dev.Registry.search`, {class}`~lamindb.File.stage`, {class}`~lamindb.File.backed`, {class}`~lamindb.File.load`
  - {class}`~lamindb.dev.CanValidate.validate` & {class}`~lamindb.dev.CanValidate.standardize` metadata of vectors & arrays, {class}`~lamindb.dev.CanValidate.inspect` validation failures
  - register & annotate: use {class}`~lamindb.dev.LabelManager.add` to annotate with untyped or typed labels, {class}`~lamindb.File.save` to save data & metadata
- {meth}`~lamindb.track` data flow (provenance/ lineage) across notebooks, pipelines & UI
- Manage ontologies, embed custom ontologies in public knowledge
- Model data schema-less or schema-full, add custom schema plug-ins, manage schema migrations
- No silos: create DB instances within seconds and share data across a mesh of instances
- Awareness of common array formats in memory & storage: `DataFrame`, `AnnData`, `MuData`, `pyarrow.Table` backed by `parquet`, `zarr`, `TileDB`, `HDF5`
  - `.backed()` provides access to connectors that allow stream-based queries
  - `.join()` allows auto-concatenating DataFrames

**How?**

- Zero lock-in: universal, simple storage formats, LaminDB is **not** a client for "Lamin Cloud" but can run server-side allowing you to build your own apps
- Scalable: metadata tables support 100s of millions of entries at reasonable query speed, otherwise Lamin relies on object stores
- Flexible storage backends (local, S3, GCP, anything `fsspec` supports)
- Currently two SQL backends: SQLite & Postgres (more to come)
- Fine-grained access management via embedded storage & SQL restrictions & high-level access management through Lamin's collaborator roles
- Secure: fully secure & embedded in your infrastructure & Lamin has no access to your data & metadata
- Idempotent & ACID operations
- File & dataset versioning
- Numerous safeguards against typos & duplications when populating
- A small number of high-quality dependencies

**Principles & assumptions**

1. Data is generated by instruments that process physical samples: it comes in batches stored in files.
2. Data batches (files) are transformed into more useful data representations, either:
   a. Summary statistics like count matrices for fastq files
   b. Array stores of non-array-like input data (say images)
   c. High-level embeddings for lower-level array, text or graph representations
3. Semantics of high-level embeddings ("inflammatory", "lipophile") are typically anchored in experimental metadata and ontologies
4. Experimental metadata is just another ontology type
5. ...
